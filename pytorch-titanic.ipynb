{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-15T18:36:11.577650Z","iopub.status.busy":"2023-12-15T18:36:11.576570Z","iopub.status.idle":"2023-12-15T18:36:11.587718Z","shell.execute_reply":"2023-12-15T18:36:11.586441Z","shell.execute_reply.started":"2023-12-15T18:36:11.577565Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on Kaggle: False\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","\n","is_kaggle = \"KAGGLE_WORKING_DIR\" in os.environ or \"/kaggle\" in os.getcwd()\n","print(\"Running on Kaggle:\", is_kaggle)\n","\n","if is_kaggle:\n","    data_path = \"/kaggle/input/titanic/\"\n","else:\n","    data_path = os.getcwd() + \"/\""]},{"cell_type":"markdown","metadata":{},"source":["Based on fast.ai chapter 5 we'll now iterate on the numpy-titanic notebook by using pytorch and applying some best practices from that chapter"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Data set"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.590356Z","iopub.status.busy":"2023-12-15T18:36:11.590031Z","iopub.status.idle":"2023-12-15T18:36:11.627922Z","shell.execute_reply":"2023-12-15T18:36:11.626658Z","shell.execute_reply.started":"2023-12-15T18:36:11.590329Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass  \\\n","0              1         0       3   \n","1              2         1       1   \n","2              3         1       3   \n","3              4         1       1   \n","4              5         0       3   \n","..           ...       ...     ...   \n","886          887         0       2   \n","887          888         1       1   \n","888          889         0       3   \n","889          890         1       1   \n","890          891         0       3   \n","\n","                                                  Name     Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    male  22.0      1   \n","1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                               Heikkinen, Miss. Laina  female  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                             Allen, Mr. William Henry    male  35.0      0   \n","..                                                 ...     ...   ...    ...   \n","886                              Montvila, Rev. Juozas    male  27.0      0   \n","887                       Graham, Miss. Margaret Edith  female  19.0      0   \n","888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n","889                              Behr, Mr. Karl Howell    male  26.0      0   \n","890                                Dooley, Mr. Patrick    male  32.0      0   \n","\n","     Parch            Ticket     Fare Cabin Embarked  \n","0        0         A/5 21171   7.2500   NaN        S  \n","1        0          PC 17599  71.2833   C85        C  \n","2        0  STON/O2. 3101282   7.9250   NaN        S  \n","3        0            113803  53.1000  C123        S  \n","4        0            373450   8.0500   NaN        S  \n","..     ...               ...      ...   ...      ...  \n","886      0            211536  13.0000   NaN        S  \n","887      0            112053  30.0000   B42        S  \n","888      2        W./C. 6607  23.4500   NaN        S  \n","889      0            111369  30.0000  C148        C  \n","890      0            370376   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(data_path + \"train.csv\")\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### Handling na values\n","For linear regression to work we need numerical values, n/a values are not numerical so we should check if our data set contain them."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We should avoid removing columns or rows. Even the absence of data can sometimes indicate a pattern.\n","\n","There are many ways to substitute na_values, the easiest of which is to replace na values with the mode value (the most commonly occuring value). This is a good starting point as usually the method of substituion doesn't have a large impact on our results so the mode is good to get an MVP up and running we can iterate on."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId                      1\n","Survived                       0.0\n","Pclass                         3.0\n","Name           Abbing, Mr. Anthony\n","Sex                           male\n","Age                           24.0\n","SibSp                          0.0\n","Parch                          0.0\n","Ticket                        1601\n","Fare                          8.05\n","Cabin                      B96 B98\n","Embarked                         S\n","Name: 0, dtype: object"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["modes = df.mode().iloc[0]\n","modes"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Embarked       0\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.fillna(modes, inplace=True)\n","df.isna().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def substitue_na_with_modes(df: pd.DataFrame) -> pd.DataFrame:\n","    modes = df.mode().iloc[0]\n","    return df.fillna(modes)"]},{"cell_type":"markdown","metadata":{},"source":["### Converting Category Data to Binary Categorical Values\n"]},{"cell_type":"markdown","metadata":{},"source":["We can get view our non-numeric or numberic data using the describe function.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Ticket</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>891</td>\n","      <td>2</td>\n","      <td>681</td>\n","      <td>147</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>347082</td>\n","      <td>B96 B98</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>577</td>\n","      <td>7</td>\n","      <td>691</td>\n","      <td>646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Name   Sex  Ticket    Cabin Embarked\n","count                       891   891     891      891      891\n","unique                      891     2     681      147        3\n","top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n","freq                          1   577       7      691      646"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=object)"]},{"cell_type":"markdown","metadata":{},"source":["Sex and Embarked only have 2, and 3 unique values respectively. It's safe to say these are categorical values.\n","\n","We should also check if any of our numbers are categorical"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>28.566970</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.199572</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId    Survived      Pclass         Age       SibSp  \\\n","count   891.000000  891.000000  891.000000  891.000000  891.000000   \n","mean    446.000000    0.383838    2.308642   28.566970    0.523008   \n","std     257.353842    0.486592    0.836071   13.199572    1.102743   \n","min       1.000000    0.000000    1.000000    0.420000    0.000000   \n","25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n","50%     446.000000    0.000000    3.000000   24.000000    0.000000   \n","75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n","max     891.000000    1.000000    3.000000   80.000000    8.000000   \n","\n","            Parch        Fare  \n","count  891.000000  891.000000  \n","mean     0.381594   32.204208  \n","std      0.806057   49.693429  \n","min      0.000000    0.000000  \n","25%      0.000000    7.910400  \n","50%      0.000000   14.454200  \n","75%      0.000000   31.000000  \n","max      6.000000  512.329200  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=(np.number))"]},{"cell_type":"markdown","metadata":{},"source":["We can see from its quarile values that PClass is likely also categorical despite being numeric as its only values are 1, 2 or 3. We can confirm this by looking at the [data dictionary](https://www.kaggle.com/competitions/titanic/data) for the kaggle competition and by via pandas.\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["array([3, 1, 2])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.Pclass.unique()"]},{"cell_type":"markdown","metadata":{},"source":["\n","Sex, the Passenger class and Embarking city are not measurable attributes so we should convert them to Boolean numbers that can be used as co-efficients. In the previous notebook we did this manually however this pandas can do this for us using `Dataframe.get_dummies()`"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.664903Z","iopub.status.busy":"2023-12-15T18:36:11.664551Z","iopub.status.idle":"2023-12-15T18:36:11.691977Z","shell.execute_reply":"2023-12-15T18:36:11.690666Z","shell.execute_reply.started":"2023-12-15T18:36:11.664869Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket',\n","       'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n","       'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3'],\n","      dtype='object')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","df = pd.get_dummies(df, columns=categorical_feature_names)\n","df.columns"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Pclass_1  \\\n","0       False      True       False       False        True     False   \n","1        True     False        True       False       False      True   \n","2        True     False       False       False        True     False   \n","3        True     False       False       False        True      True   \n","4       False      True       False       False        True     False   \n","\n","   Pclass_2  Pclass_3  \n","0     False      True  \n","1     False     False  \n","2     False      True  \n","3     False     False  \n","4     False      True  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["dummy_column_names = ['Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n","       'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3']\n","df[dummy_column_names].head()"]},{"cell_type":"markdown","metadata":{},"source":["### Converting numbers to fractional values\n","#### Age\n","Larger numbers would have too great an impact on our calculations so we can normalize them by dividing them by their max value them so they're between 0 and 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.746963Z","iopub.status.busy":"2023-12-15T18:36:11.746619Z","iopub.status.idle":"2023-12-15T18:36:11.769574Z","shell.execute_reply":"2023-12-15T18:36:11.768464Z","shell.execute_reply.started":"2023-12-15T18:36:11.746934Z"},"trusted":true},"outputs":[],"source":["def convert_numeric_column_to_decimal(old_df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    max_numeric_value = old_df[column_name].max()\n","    new_df[column_name] = old_df[column_name].apply(lambda x: x/max_numeric_value)\n","    return new_df\n","    \n","training_dataframe = convert_numeric_column_to_decimal(training_dataframe, \"Age\")\n","training_dataframe.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["#### Fare\n","The `Fare` column has lots of small values with the occasional very large value. Uniform normalization using the max value isn't ideal when we're dealing with lots of small values with occasional very large values as the variation between the lower numbers will be lost. To normalize the values we can use a log function (log10 here) to bring the numbers down to reasonable ranges. We must use `log10(x+1)` to avoid 0 values as `log10(0)` would give us infinity."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.771533Z","iopub.status.busy":"2023-12-15T18:36:11.771187Z","iopub.status.idle":"2023-12-15T18:36:11.795392Z","shell.execute_reply":"2023-12-15T18:36:11.794544Z","shell.execute_reply.started":"2023-12-15T18:36:11.771504Z"},"trusted":true},"outputs":[],"source":["import math\n","def convert_numeric_column_to_decimal_with_logarithm(old_df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df[column_name] = new_df[column_name].apply(lambda x: math.log10(x+1) if x > 0 else 0)\n","    new_df = convert_numeric_column_to_decimal(new_df, column_name)\n","    return new_df\n","\n","training_dataframe = convert_numeric_column_to_decimal_with_logarithm(training_dataframe, \"Fare\")\n","training_dataframe.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["## Linear Regression\n","### Add a constant value\n","A linear function needs a constant, this will be needed for the maths so we should add a column full of ones"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.800280Z","iopub.status.busy":"2023-12-15T18:36:11.799914Z","iopub.status.idle":"2023-12-15T18:36:11.818268Z","shell.execute_reply":"2023-12-15T18:36:11.816933Z","shell.execute_reply.started":"2023-12-15T18:36:11.800248Z"},"trusted":true},"outputs":[],"source":["training_dataframe[\"Constant\"] = 1\n","training_dataframe.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare initial linear co-efficient values\n","We want to set each of our parameter values to a random number close to 1. The survived column is not a parameter but our desired result/output so we don't include this."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.820322Z","iopub.status.busy":"2023-12-15T18:36:11.819991Z","iopub.status.idle":"2023-12-15T18:36:11.833908Z","shell.execute_reply":"2023-12-15T18:36:11.832743Z","shell.execute_reply.started":"2023-12-15T18:36:11.820295Z"},"trusted":true},"outputs":[],"source":["input_df = training_dataframe.drop(\"Survived\", axis=1)\n","linear_parameters = np.random.rand(input_df.shape[1]).tolist()\n","linear_parameters"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the linear function of our parameters multiplied by our random Coefficients"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.836343Z","iopub.status.busy":"2023-12-15T18:36:11.835997Z","iopub.status.idle":"2023-12-15T18:36:11.858845Z","shell.execute_reply":"2023-12-15T18:36:11.857637Z","shell.execute_reply.started":"2023-12-15T18:36:11.836315Z"},"trusted":true},"outputs":[],"source":["def calculate_linear_result() -> np.array:\n","    return input_df.apply(lambda row: row.dot(linear_parameters), axis=1).to_numpy()\n","\n","training_dataframe[\"Initial Linear Result\"] = input_df.apply(lambda row: row.dot(linear_parameters), axis=1)\n","training_dataframe.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["### Gradient Descent"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.860841Z","iopub.status.busy":"2023-12-15T18:36:11.860409Z","iopub.status.idle":"2023-12-15T18:36:22.655866Z","shell.execute_reply":"2023-12-15T18:36:22.654577Z","shell.execute_reply.started":"2023-12-15T18:36:11.860799Z"},"trusted":true},"outputs":[],"source":["def optimize_weights(inputs: [pd.DataFrame], target_variables: np.array, parameters: [float], learning_rate: float=0.01, epochs: int=1000) -> [float]:\n","    for current_epoch in range(epochs):\n","        # Predicted values\n","        predicted_values = inputs.apply(lambda row: row.dot(parameters), axis=1).to_numpy()\n","    \n","        # Calculate error\n","        errors = predicted_values - target_variables\n","        mean_square_error = (errors ** 2).mean()\n","    \n","        if current_epoch % 100 == 0: #Print every 100th value\n","            print(mean_square_error)\n","    \n","        # Calculate gradient\n","        gradient = np.dot(inputs.to_numpy().T, errors) * 2 / len(target_variables)\n","    \n","        # Update parameters\n","        parameters -= learning_rate * gradient\n","    # Final parameters\n","    print(f\"Optimized weights: {parameters}\")\n","    print(f\"Final error: {mean_square_error}\")\n","    return parameters\n","    \n","linear_parameters = optimize_weights(inputs=input_df, target_variables=training_dataframe[\"Survived\"].to_numpy(), parameters=linear_parameters)"]},{"cell_type":"markdown","metadata":{},"source":["## Neural Nets\n","The calculation above was a linear regression as we only use one set of parameters.\n","Here we'll use two sets of parameters, apply a RELU (Rectified Linear Unit) function and add them together to give us a loss. A RELU function is non-linear and simply replaces every negative number with a 0.\n","\n","The RELU is needed as adding together two linear functions just gives us another linear function which doesn't give us any more resolution for our calculation. Combinging each linear layer with a non-linear RELU allows us to keep each linear functions utility increasing our algortihms accuracy."]},{"cell_type":"markdown","metadata":{},"source":["### Create Matrix of Relu Values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.660525Z","iopub.status.busy":"2023-12-15T18:36:22.659415Z","iopub.status.idle":"2023-12-15T18:36:22.666015Z","shell.execute_reply":"2023-12-15T18:36:22.664952Z","shell.execute_reply.started":"2023-12-15T18:36:22.660473Z"},"trusted":true},"outputs":[],"source":["np.random.seed(42)\n","parameter_matrix = np.random.rand(2, input_df.shape[1]) - 0.5\n","known_survival_matrix = training_dataframe[\"Survived\"].to_numpy().reshape(-1,1)\n","inputs = input_df.to_numpy()\n","inputs"]},{"cell_type":"markdown","metadata":{},"source":["### Relu Gradient Descent (non-linear)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.667248Z","iopub.status.busy":"2023-12-15T18:36:22.666958Z","iopub.status.idle":"2023-12-15T18:36:22.786974Z","shell.execute_reply":"2023-12-15T18:36:22.785761Z","shell.execute_reply.started":"2023-12-15T18:36:22.667223Z"},"trusted":true},"outputs":[],"source":["# Gradient descent\n","for current_epoch in range(1000):\n","    # Predicted values\n","    predicted_value_matrix = np.dot(inputs, parameter_matrix.T)\n","    relu_value_matrix = np.maximum(predicted_value_matrix, 0)\n","    \n","    # Calculate error\n","    errors = relu_value_matrix - known_survival_matrix\n","    summed_errors = np.sum(errors, axis=1)\n","    if current_epoch % 100 == 0: #Print every 100th value\n","        print(summed_errors.mean())\n","    \n","    # Calculate gradient\n","    gradient = np.dot(inputs.T, summed_errors) * 2 / len(training_dataframe[\"Survived\"].to_numpy())\n","    \n","    # Update parameters\n","    parameter_matrix -= 0.01 * gradient\n","    nn_params = parameter_matrix.sum(axis=0)\n","\n","# Final parameters\n","print(f\"Optimized weights: {nn_params}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create Titanic survial predictions"]},{"cell_type":"markdown","metadata":{},"source":["Now we'll use the parameters we've calculated to try and make predictions about the survivors in our validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.788466Z","iopub.status.busy":"2023-12-15T18:36:22.788155Z","iopub.status.idle":"2023-12-15T18:36:22.814972Z","shell.execute_reply":"2023-12-15T18:36:22.813815Z","shell.execute_reply.started":"2023-12-15T18:36:22.788438Z"},"trusted":true},"outputs":[],"source":["serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.819159Z","iopub.status.busy":"2023-12-15T18:36:22.816741Z","iopub.status.idle":"2023-12-15T18:36:22.864182Z","shell.execute_reply":"2023-12-15T18:36:22.862846Z","shell.execute_reply.started":"2023-12-15T18:36:22.819120Z"},"trusted":true},"outputs":[],"source":["def estimate_missing_ages(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    mean_age = old_df[\"Age\"].mean()\n","    new_df[\"Age\"].fillna(value=mean_age, inplace=True)\n","    return new_df\n","\n","def estimate_missing_fares(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df[\"Fare\"].fillna(value=0, inplace=True)\n","    return new_df\n","    \n","def prepare_data(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df = remove_irrelevant_data(new_df)\n","    new_df = estimate_missing_ages(new_df)\n","    new_df = estimate_missing_fares(new_df)\n","    print(\"Searching for NA values:\")\n","    print(new_df.isna().any())\n","    new_df = convert_ticket_class_to_binary_values(new_df)\n","    new_df = convert_embarkation_port_to_binary_values(new_df)\n","    new_df = convert_sex_to_binary_value(new_df)\n","    new_df = convert_numeric_column_to_decimal(new_df, \"Age\")\n","    new_df = convert_numeric_column_to_decimal_with_logarithm(new_df, \"Fare\")\n","    new_df[\"Constant\"] = 1\n","    return new_df\n","    \n","serving_df = prepare_data(serving_df)\n","assert (input_df.columns == serving_df.columns).all()\n","serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.866861Z","iopub.status.busy":"2023-12-15T18:36:22.866374Z","iopub.status.idle":"2023-12-15T18:36:22.890775Z","shell.execute_reply":"2023-12-15T18:36:22.889549Z","shell.execute_reply.started":"2023-12-15T18:36:22.866818Z"},"trusted":true},"outputs":[],"source":["def create_predictions(validation_df: pd.DataFrame, optimized_weights: np.array) -> np.array:\n","    return np.dot(validation_df.to_numpy(), optimized_weights)\n","\n","serving_df[\"Survival Prediction\"] = create_predictions(serving_df, nn_params)\n","serving_df"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Submission CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.892540Z","iopub.status.busy":"2023-12-15T18:36:22.892207Z","iopub.status.idle":"2023-12-15T18:36:22.919481Z","shell.execute_reply":"2023-12-15T18:36:22.918559Z","shell.execute_reply.started":"2023-12-15T18:36:22.892511Z"},"trusted":true},"outputs":[],"source":["original_validation_df = pd.read_csv(data_path + \"test.csv\")\n","submission_df = pd.DataFrame()\n","submission_df[\"PassengerId\"] = original_validation_df[\"PassengerId\"]\n","submission_df[\"Survived\"] = serving_df[\"Survival Prediction\"].apply(lambda x: 0 if x < 0.5 else 1)\n","submission_df.to_csv(\"submission.csv\", index=False)\n","submission_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
