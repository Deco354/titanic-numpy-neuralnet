{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-15T18:36:11.577650Z","iopub.status.busy":"2023-12-15T18:36:11.576570Z","iopub.status.idle":"2023-12-15T18:36:11.587718Z","shell.execute_reply":"2023-12-15T18:36:11.586441Z","shell.execute_reply.started":"2023-12-15T18:36:11.577565Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on Kaggle: False\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","\n","is_kaggle = \"KAGGLE_WORKING_DIR\" in os.environ or \"/kaggle\" in os.getcwd()\n","print(\"Running on Kaggle:\", is_kaggle)\n","\n","if is_kaggle:\n","    data_path = \"/kaggle/input/titanic/\"\n","else:\n","    data_path = os.getcwd() + \"/\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","np.set_printoptions(linewidth=140)\n","torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n","pd.set_option('display.width', 140)"]},{"cell_type":"markdown","metadata":{},"source":["Based on fast.ai chapter 5 we'll now iterate on the numpy-titanic notebook by using pytorch and applying some best practices from that chapter"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Data set"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.590356Z","iopub.status.busy":"2023-12-15T18:36:11.590031Z","iopub.status.idle":"2023-12-15T18:36:11.627922Z","shell.execute_reply":"2023-12-15T18:36:11.626658Z","shell.execute_reply.started":"2023-12-15T18:36:11.590329Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n","0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n","1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n","2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n","3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n","4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n","..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n","886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n","887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n","888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n","889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n","890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n","\n","        Fare Cabin Embarked  \n","0     7.2500   NaN        S  \n","1    71.2833   C85        C  \n","2     7.9250   NaN        S  \n","3    53.1000  C123        S  \n","4     8.0500   NaN        S  \n","..       ...   ...      ...  \n","886  13.0000   NaN        S  \n","887  30.0000   B42        S  \n","888  23.4500   NaN        S  \n","889  30.0000  C148        C  \n","890   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(data_path + \"train.csv\")\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### Handling na values\n","For linear regression to work we need numerical values, n/a values are not numerical so we should check if our data set contain them."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We should avoid removing columns or rows. Even the absence of data can sometimes indicate a pattern.\n","\n","There are many ways to substitute na_values, the easiest of which is to replace na values with the mode value (the most commonly occuring value). This is a good starting point as usually the method of substituion doesn't have a large impact on our results so the mode is good to get an MVP up and running we can iterate on."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId                      1\n","Survived                       0.0\n","Pclass                         3.0\n","Name           Abbing, Mr. Anthony\n","Sex                           male\n","Age                           24.0\n","SibSp                          0.0\n","Parch                          0.0\n","Ticket                        1601\n","Fare                          8.05\n","Cabin                      B96 B98\n","Embarked                         S\n","Name: 0, dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["modes = df.mode().iloc[0]\n","modes"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Embarked       0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.fillna(modes, inplace=True)\n","df.isna().sum()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def substitue_na_with_modes(df: pd.DataFrame) -> pd.DataFrame:\n","    modes = df.mode().iloc[0]\n","    return df.fillna(modes)"]},{"cell_type":"markdown","metadata":{},"source":["### Converting Category Data to Binary Categorical Values\n"]},{"cell_type":"markdown","metadata":{},"source":["We can get view our non-numeric or numberic data using the describe function.\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Ticket</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>891</td>\n","      <td>2</td>\n","      <td>681</td>\n","      <td>147</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>347082</td>\n","      <td>B96 B98</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>577</td>\n","      <td>7</td>\n","      <td>691</td>\n","      <td>646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Name   Sex  Ticket    Cabin Embarked\n","count                       891   891     891      891      891\n","unique                      891     2     681      147        3\n","top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n","freq                          1   577       7      691      646"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=object)"]},{"cell_type":"markdown","metadata":{},"source":["Sex and Embarked only have 2, and 3 unique values respectively. It's safe to say these are categorical values.\n","\n","We should also check if any of our numbers are categorical"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>28.566970</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.199572</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n","count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n","mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n","std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n","min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n","25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n","50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n","75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n","max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=(np.number))"]},{"cell_type":"markdown","metadata":{},"source":["We can see from its quarile values that PClass is likely also categorical despite being numeric as its only values are 1, 2 or 3. We can confirm this by looking at the [data dictionary](https://www.kaggle.com/competitions/titanic/data) for the kaggle competition and by via pandas.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([3, 1, 2])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.Pclass.unique()"]},{"cell_type":"markdown","metadata":{},"source":["\n","Sex, the Passenger class and Embarking city are not measurable attributes so we should convert them to Boolean numbers that can be used as co-efficients. In the previous notebook we did this manually however this pandas can do this for us using `Dataframe.get_dummies()`"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.664903Z","iopub.status.busy":"2023-12-15T18:36:11.664551Z","iopub.status.idle":"2023-12-15T18:36:11.691977Z","shell.execute_reply":"2023-12-15T18:36:11.690666Z","shell.execute_reply.started":"2023-12-15T18:36:11.664869Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Embarked_C',\n","       'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3'],\n","      dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","df = pd.get_dummies(df, columns=categorical_feature_names, dtype=int)\n","df.columns"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0         1           0         0         0         1           0           0           1\n","1         0           1         1         0         0           1           0           0\n","2         0           1         0         0         1           0           0           1\n","3         0           1         1         0         0           0           0           1\n","4         1           0         0         0         1           0           0           1"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["dummy_column_names = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q',\n","       'Embarked_S']\n","df[dummy_column_names].head()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def convert_categories_to_binary_values(df: pd.DataFrame) -> pd.DataFrame:\n","    categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","    return pd.get_dummies(df, columns=categorical_feature_names, dtype=int)"]},{"cell_type":"markdown","metadata":{},"source":["### Handling long-tail numerical data"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib\n","df.Fare.hist()"]},{"cell_type":"markdown","metadata":{},"source":["The `Fare` column has lots of small values with the occasional very large value. Uniform normalization using the max value isn't ideal when we're dealing with lots of small values with occasional very large values as the variation between the lower numbers will be lost. To normalize the values we can use a log function (log10 here) to bring the numbers down to reasonable ranges. We must use `log10(x+1)` to avoid 0 values as `log10(0)` would give us infinity."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.771533Z","iopub.status.busy":"2023-12-15T18:36:11.771187Z","iopub.status.idle":"2023-12-15T18:36:11.795392Z","shell.execute_reply":"2023-12-15T18:36:11.794544Z","shell.execute_reply.started":"2023-12-15T18:36:11.771504Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import math\n","df['LogFare'] = np.log(df['Fare'] + 1)\n","df.LogFare.hist()"]},{"cell_type":"markdown","metadata":{},"source":["## Linear Regression"]},{"cell_type":"markdown","metadata":{},"source":["### Pytorch Tensors\n","For our gradient descent we'll be using Pytorch rather than numpy for this workbook as it will do a lot of the heavy lifting for us. Alongside Tensorflow pytorch is the most commonly used framework for machine learning."]},{"cell_type":"markdown","metadata":{},"source":["We'll start by creating Tensors for our target values (known survival status) and features (our numerical data)."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n","        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n","        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n","        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n","        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n","        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n","        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n","        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n","        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n","        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n","        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from torch import tensor\n","target_tensor = tensor(df.Survived)\n","target_tensor"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>LogFare</th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2.110213</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4.280593</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.188856</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3.990834</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.202765</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.639057</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.433987</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>24.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3.196630</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.433987</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.169054</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["      Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0    22.0      1      0  2.110213         1           0         0         0         1           0           0           1\n","1    38.0      1      0  4.280593         0           1         1         0         0           1           0           0\n","2    26.0      0      0  2.188856         0           1         0         0         1           0           0           1\n","3    35.0      1      0  3.990834         0           1         1         0         0           0           0           1\n","4    35.0      0      0  2.202765         1           0         0         0         1           0           0           1\n","..    ...    ...    ...       ...       ...         ...       ...       ...       ...         ...         ...         ...\n","886  27.0      0      0  2.639057         1           0         0         1         0           0           0           1\n","887  19.0      0      0  3.433987         0           1         1         0         0           0           0           1\n","888  24.0      1      2  3.196630         0           1         0         0         1           0           0           1\n","889  26.0      0      0  3.433987         1           0         1         0         0           1           0           0\n","890  32.0      0      0  2.169054         1           0         0         0         1           0           1           0\n","\n","[891 rows x 12 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["feature_names = ['Age', 'SibSp', 'Parch', 'LogFare'] + dummy_column_names\n","feature_df = df[feature_names]\n","feature_df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        ...,\n","        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["features = feature_df.values\n","feature_tensor = tensor(features, dtype=torch.float)\n","feature_tensor"]},{"cell_type":"markdown","metadata":{},"source":["### Normalization\n","Once all our features are numerical we need to ensure they're somewhat uniform. For Linear regression and many other ML methods having some features be much larger than others will disrupt the process. Rather than do this manually we can have Pytorch do this for us."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([80.0000,  8.0000,  6.0000,  6.2409,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["max_values, max_indices = feature_tensor.max(dim=0)\n","max_values"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.0000, 0.0000, 0.3600, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.6750, 0.0000, 0.0000, 0.6358, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        ...,\n","        [0.3125, 0.0000, 0.0000, 0.3342, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4875, 0.0000, 0.8333, 0.5456, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.3375, 0.0000, 0.0000, 0.4229, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.2375, 0.0000, 0.0000, 0.5502, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.1250, 0.3333, 0.5122, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3250, 0.0000, 0.0000, 0.5502, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.4000, 0.0000, 0.0000, 0.3476, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["feature_tensor = feature_tensor / max_values\n","feature_tensor"]},{"cell_type":"markdown","metadata":{},"source":["#### Broadcasting\n","`feature_tensor / max_values` is an example of [broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html). \n","`max_values` is a one dimensional vector with shape (12). `feature_tensor` is a 2 dimensional matrix with shape (892,12). Because `max_values` is the same size as one of `feature_tensor`'s it will be applied to all 891 rows of `feature_tensor`\n","\n","Broadcasting is useful for large datasets. The calculations are optimized and run on a GPU when available."]},{"cell_type":"markdown","metadata":{},"source":["### Prepare initial linear co-efficient values\n","For linear regression we'd like a one dimensional vector of coefficients equal to our number of rows. Unlike in previous examples we don't need a constant as our dummy variables effectively act as a constant."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.820322Z","iopub.status.busy":"2023-12-15T18:36:11.819991Z","iopub.status.idle":"2023-12-15T18:36:11.833908Z","shell.execute_reply":"2023-12-15T18:36:11.832743Z","shell.execute_reply.started":"2023-12-15T18:36:11.820295Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(442)\n","coefficient_count = feature_tensor.shape[1]\n","coefficients = torch.rand(coefficient_count) - 0.5\n","coefficients"]},{"cell_type":"markdown","metadata":{},"source":["Generally we don't want to set a manual seed so we can be aware of how stable our data is or isn't. However for the sake of this lesson I'd like to check I'm getting consistent results with the lesson plan."]},{"cell_type":"markdown","metadata":{},"source":["### Create Predictions\n","We calculate the linear function of our parameters by multiplied them against our random Coefficients then summing each row of weighted values up to create a prediction for each passenger\n","Pytorch's broadcasting can once again be used here to simplify things considerably. We'll print it out to check there aren't any weighted values that are significantly oversized."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.836343Z","iopub.status.busy":"2023-12-15T18:36:11.835997Z","iopub.status.idle":"2023-12-15T18:36:11.858845Z","shell.execute_reply":"2023-12-15T18:36:11.857637Z","shell.execute_reply.started":"2023-12-15T18:36:11.836315Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n","        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["weighted_values = feature_tensor * coefficients\n","weighted_values[:4]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["predictions = weighted_values.sum(dim=1)\n","predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate loss\n","Our loss here is the average difference between our prediction value and whether the passegner survived or not (1 or 0)."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["loss = torch.abs(predictions - target_tensor).mean()\n","loss"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def calculate_loss(features: torch.Tensor, coefficients: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    return torch.abs(predictions - targets).mean()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    return (coefficients * features).sum(axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Doing a single Gradient Descent step\n","Now we want to optimize our loss with gradient descent. This too will be significantly easier using Pytorch as it will calculate the gradient for us.\n","\n","We must tell pytorch to store the results of each coefficient calculation so we can get the gradients from it later."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.860841Z","iopub.status.busy":"2023-12-15T18:36:11.860409Z","iopub.status.idle":"2023-12-15T18:36:22.655866Z","shell.execute_reply":"2023-12-15T18:36:22.654577Z","shell.execute_reply.started":"2023-12-15T18:36:11.860799Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["coefficients.requires_grad_()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382, grad_fn=<MeanBackward0>)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss"]},{"cell_type":"markdown","metadata":{},"source":["The loss is in a tensor where can ask Pytorch to calculate the gradient by calling `backward()`"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["loss.backward()\n","coefficients.grad"]},{"cell_type":"markdown","metadata":{},"source":["Here we perform one gradient descent step\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.5197)\n"]}],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss.backward\n","with torch.no_grad():\n","    coefficients.sub_(coefficients.grad * 0.1)\n","    coefficients.grad.zero_()\n","    print(calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor))"]},{"cell_type":"markdown","metadata":{},"source":["A few points:\n","1. `torch.no_grad()` is required to ensure the parameter update step is peformed without tracking gradients. We want to track gradients for the forward and backward steps but not when directly modifying the parameters\n","2. `coefficients.sub_(coefficients.grad * 0.1)` reduces the coefficients by their gradient to the loss. More significant features will be reduced more. \n","3. Both `sub_` and `zero_` operations are done in place for memory efficiency and to preserve the tensors memory graph (this is also ensured by `torch.no_grad()` although it's good practice when working with tensors).\n","4. `coefficients.grad.zero_()` sets our gradients to zero. This is necessary as if we were to do another backpass the new gradients would be added to the old ones."]},{"cell_type":"markdown","metadata":{},"source":["### Creating a validation set\n"]},{"cell_type":"markdown","metadata":{},"source":["Before we begin training we need a validation set to compare our training data against."]},{"cell_type":"markdown","metadata":{},"source":["I've deviated from the [fast.ai kaggle workbook](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch) as they split their validation set using the fastai library to keep things consistent for their next chapter. I'm interested in primarily learning Pytorch so I'm going to split the dataset without the fastai library. However so I can check if my results match fast.ai's I'm going to include their splitter here it will be used if `use_fastai_splitter` is set to `True` so I can check my results are consistent with the fast.ai tutorials."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["from numpy import int64\n","from fastai.data.transforms import RandomSplitter\n","\n","def split_data_with_fastai(df: pd.DataFrame) -> tuple[np.int64, np.int64]:\n","    return RandomSplitter(seed=42)(df)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["First we'll split our data"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["(713, 178)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["use_fastai_splitter = True\n","total_passengers = feature_tensor.size(0)\n","training_set_size = int(total_passengers * 0.8)\n","\n","if use_fastai_splitter:\n","    train_indices, validation_indices = split_data_with_fastai(df)\n","else:\n","    randomized_indices = torch.randperm(total_passengers)\n","    train_indices = randomized_indices[:training_set_size]\n","    validation_indices = randomized_indices[training_set_size:]\n","\n","training_features = feature_tensor[train_indices]\n","validation_features = feature_tensor[validation_indices]\n","training_targets = target_tensor[train_indices]\n","validation_targets = target_tensor[validation_indices]\n","len(training_features), len(validation_features)"]},{"cell_type":"markdown","metadata":{},"source":["This note book doesn't use Pytorch's `Dataset`s. We'd likely use these in a real project although for this example we're keeping things a bit barer than normal so we can see the process."]},{"cell_type":"markdown","metadata":{},"source":["We'll add what we've done so far in to functions to make things easier to read and re-usable."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["def update_coefficients(coefficients: torch.Tensor, learning_rate):\n","    coefficients.sub_(coefficients.grad * learning_rate)\n","    coefficients.grad.zero_()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def one_epoch(coefficients, learning_rate):\n","    loss = calculate_loss(training_features, coefficients, training_targets)\n","    loss.backward()\n","    with torch.no_grad():\n","        update_coefficients(coefficients, learning_rate=learning_rate)\n","        \n","    print(f\"{loss:.3f}\", end=\"; \")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def generate_coefficients(features: torch.Tensor) -> torch.Tensor:\n","    coefficient_count = features.shape[1]\n","    coefficients = torch.rand(coefficient_count) - 0.5\n","    coefficients.requires_grad_()\n","    return coefficients"]},{"cell_type":"markdown","metadata":{},"source":["Now to train the model"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def train_model(epoch_count=30, learning_rate=0.1):\n","    coefficients = generate_coefficients(training_features)\n","    for i in range(epoch_count):\n","        one_epoch(coefficients, learning_rate=learning_rate)\n","    return coefficients"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.550; 0.494; 0.446; 0.400; 0.385; 0.392; 0.348; 0.351; 0.365; 0.327; 0.345; 0.310; 0.326; 0.292; 0.308; 0.280; 0.323; 0.269; "]},{"data":{"text/plain":["tensor([ 0.0114, -0.1277, -0.0490,  0.2052,  0.0136,  0.7174,  0.0278, -0.1602, -0.1642,  0.1394,  0.3767,  0.2155], requires_grad=True)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["coefficients = train_model(epoch_count=18, learning_rate=0.2)\n","coefficients"]},{"cell_type":"markdown","metadata":{},"source":["We can see below that our models has optimized our weights to reduce our loss. From this we can see that the model believes"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature</th>\n","      <th>Coefficient</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Age</td>\n","      <td>0.011448</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SibSp</td>\n","      <td>-0.127748</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Parch</td>\n","      <td>-0.049038</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LogFare</td>\n","      <td>0.205193</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sex_male</td>\n","      <td>0.013623</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sex_female</td>\n","      <td>0.717442</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Pclass_1</td>\n","      <td>0.027782</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Pclass_2</td>\n","      <td>-0.160171</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Pclass_3</td>\n","      <td>-0.164208</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Embarked_C</td>\n","      <td>0.139427</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Embarked_Q</td>\n","      <td>0.376680</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Embarked_S</td>\n","      <td>0.215454</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Feature  Coefficient\n","0          Age     0.011448\n","1        SibSp    -0.127748\n","2        Parch    -0.049038\n","3      LogFare     0.205193\n","4     Sex_male     0.013623\n","5   Sex_female     0.717442\n","6     Pclass_1     0.027782\n","7     Pclass_2    -0.160171\n","8     Pclass_3    -0.164208\n","9   Embarked_C     0.139427\n","10  Embarked_Q     0.376680\n","11  Embarked_S     0.215454"]},"metadata":{},"output_type":"display_data"}],"source":["def show_coeffs(): \n","    coeff_array = [coeff.item() for coeff in coefficients]\n","    coeff_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coeff_array})\n","    display(coeff_df)\n","show_coeffs()"]},{"cell_type":"markdown","metadata":{},"source":["### Measuring accuracy"]},{"cell_type":"markdown","metadata":{},"source":["To view our accuracy we'll now use our validation set. We'll create predictions using our newly trained coefficients and see how accurate they are."]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1.0226, 0.3008, 0.0616, 0.2132, 0.1593, 0.1594, 0.7728, 0.8635, 0.0960, 0.7756], grad_fn=<SliceBackward0>)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["predictions = create_predictions(validation_features, coefficients=coefficients)\n","predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["If our predictions is >0.5 and the passegner surivied we're correct. If the passenger died we want a prediction < 0.5. 0 = died, 1 = survived. This code merely rounds our predictions to whichever of these values is closest"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.7865)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["results = validation_targets.bool() == (predictions>0.5)\n","results.float().mean()"]},{"cell_type":"markdown","metadata":{},"source":["We're 79% accurate which is pretty good going."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["from torch import Tensor\n","\n","\n","def calculate_accuracy(coefficients, features: torch.Tensor) -> float:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    results = validation_targets.bool() == (predictions>0.5)\n","    return results.float().mean()"]},{"cell_type":"markdown","metadata":{},"source":["### Sigmoid\n","When creating predictions that are between 0 and 1 we can increase our accuracy by using the sigmoid function which moves all our values between 0 and 1 and larger negative or positives values will respectively asymptotically converge towards 0 or 1."]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<sympy.plotting.plot.Plot at 0x144e5fe80>"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["import sympy\n","sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    summed_weighted_values = (coefficients * features).sum(axis=1)\n","    return torch.sigmoid(summed_weighted_values)\n"]},{"cell_type":"markdown","metadata":{},"source":["Constricting the range of our predictions within the range of what they can realistically be makes them much easier to optimize. When this is applied to every prediction each epoch should minimize our loss more effectivelyby by eliminating values that are outside the range of what our predictions can realistically be.\n","\n","This in turn allows us to substantially increase the learning rate as our loss won't be as high or fluctuate as wildly."]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.451; 0.324; 0.299; 0.209; 0.200; 0.198; 0.197; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "]},{"data":{"text/plain":["tensor(0.8258)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["coefficients = train_model(learning_rate=100)\n","calculate_accuracy(coefficients, features=validation_features)"]},{"cell_type":"markdown","metadata":{},"source":["83% a sharp improvement!"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Submission CSV"]},{"cell_type":"markdown","metadata":{},"source":["### Using a Test set\n","Before submitting to Kaggle we'll want to test the effectiveness of our data against our test set. \n","#### Why not use the Validation set?\n","This may seem similar to how we used our validation set but there's an important difference. A validation set is used to give us an unbiased evaluation of our model's performance. Unlike a training set which is biased as we're training our model on it. As we develop our model the validation set will indirectly become biased as we iterate on our model to improve the validation sets accuracy. The test set is only ever used once we have finished developing our model so it gives us an accurate assessment of how our model behaves on completely unseen data.\n","\n","- Training set - Model bias\n","- Validation Set - Developer bias\n","- Test set - No bias"]},{"cell_type":"markdown","metadata":{},"source":["### Clean Test Data"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age             86\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             1\n","Cabin          327\n","Embarked         0\n","dtype: int64"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["test_df = pd.read_csv(data_path + 'test.csv')\n","test_df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We can use the same steps we took for cleaning the training data on our test data. However it's always worth checking if there are any additional na values. Here there's an na value for Fare that needs resolving."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Name           0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Sex_female     0\n","Sex_male       0\n","Embarked_C     0\n","Embarked_Q     0\n","Embarked_S     0\n","Pclass_1       0\n","Pclass_2       0\n","Pclass_3       0\n","LogFare        0\n","dtype: int64"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["from cgi import test\n","\n","\n","test_df.Fare.fillna(0, inplace=True)\n","test_df = substitue_na_with_modes(test_df)\n","test_df = convert_categories_to_binary_values(test_df)\n","test_df[\"LogFare\"] = np.log(test_df['Fare'] + 1)\n","test_df.isna().sum()\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>LogFare</th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.178064</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2.079442</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.369075</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.268252</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.586824</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0  34.5      0      0  2.178064         1           0         0         0         1           0           1           0\n","1  47.0      1      0  2.079442         0           1         0         0         1           0           0           1\n","2  62.0      0      0  2.369075         1           0         0         1         0           0           1           0\n","3  27.0      0      0  2.268252         1           0         0         0         1           0           0           1\n","4  22.0      1      1  2.586824         0           1         0         0         1           0           0           1"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["test_df[feature_names][:5]"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.4313, 0.0000, 0.0000, 0.3490, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.5875, 0.1250, 0.0000, 0.3332, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.7750, 0.0000, 0.0000, 0.3796, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000]])"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["test_features = tensor(test_df[feature_names].values, dtype=torch.float)\n","test_features = test_features / max_values\n","test_features[:3]"]},{"cell_type":"markdown","metadata":{},"source":["### Create test predictions"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=torch.int32)"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["with torch.no_grad():\n","    test_predictions = create_predictions(test_features, coefficients=coefficients)\n","test_predictions = (test_predictions > 0.5).int()\n","test_predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Create Kaggle submission\n","We can view the sample submission kaggle has given us to see how to format this."]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived\n","0          892         0\n","1          893         1\n","2          894         0"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["sample_df = pd.read_csv(data_path + \"gender_submission.csv\")\n","sample_df[:3]"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["PassengerId,Survived\n","892,0\n","893,1\n","894,0\n","895,0\n","896,1\n","897,0\n","898,1\n","899,0\n","900,1\n"]}],"source":["submission_df = pd.DataFrame({ \"PassengerId\": test_df[\"PassengerId\"], \"Survived\": test_predictions })\n","submission = submission_df.to_csv(index=False)\n","!head submission.csv\n"]},{"cell_type":"markdown","metadata":{},"source":["## Neural Nets\n","The calculation above was a linear regression as we only use one set of parameters.\n","Here we'll use two sets of parameters, apply a RELU (Rectified Linear Unit) function and add them together to give us a loss. A RELU function is non-linear and simply replaces every negative number with a 0.\n","\n","The RELU is needed as adding together two linear functions just gives us another linear function which doesn't give us any more resolution for our calculation. Combinging each linear layer with a non-linear RELU allows us to keep each linear functions utility increasing our algortihms accuracy."]},{"cell_type":"markdown","metadata":{},"source":["### Create Matrix of Relu Values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.660525Z","iopub.status.busy":"2023-12-15T18:36:22.659415Z","iopub.status.idle":"2023-12-15T18:36:22.666015Z","shell.execute_reply":"2023-12-15T18:36:22.664952Z","shell.execute_reply.started":"2023-12-15T18:36:22.660473Z"},"trusted":true},"outputs":[],"source":["np.random.seed(42)\n","parameter_matrix = np.random.rand(2, input_df.shape[1]) - 0.5\n","known_survival_matrix = training_dataframe[\"Survived\"].to_numpy().reshape(-1,1)\n","inputs = input_df.to_numpy()\n","inputs"]},{"cell_type":"markdown","metadata":{},"source":["### Relu Gradient Descent (non-linear)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.667248Z","iopub.status.busy":"2023-12-15T18:36:22.666958Z","iopub.status.idle":"2023-12-15T18:36:22.786974Z","shell.execute_reply":"2023-12-15T18:36:22.785761Z","shell.execute_reply.started":"2023-12-15T18:36:22.667223Z"},"trusted":true},"outputs":[],"source":["# Gradient descent\n","for current_epoch in range(1000):\n","    # Predicted values\n","    predicted_value_matrix = np.dot(inputs, parameter_matrix.T)\n","    relu_value_matrix = np.maximum(predicted_value_matrix, 0)\n","    \n","    # Calculate error\n","    errors = relu_value_matrix - known_survival_matrix\n","    summed_errors = np.sum(errors, axis=1)\n","    if current_epoch % 100 == 0: #Print every 100th value\n","        print(summed_errors.mean())\n","    \n","    # Calculate gradient\n","    gradient = np.dot(inputs.T, summed_errors) * 2 / len(training_dataframe[\"Survived\"].to_numpy())\n","    \n","    # Update parameters\n","    parameter_matrix -= 0.01 * gradient\n","    nn_params = parameter_matrix.sum(axis=0)\n","\n","# Final parameters\n","print(f\"Optimized weights: {nn_params}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create Titanic survial predictions"]},{"cell_type":"markdown","metadata":{},"source":["Now we'll use the parameters we've calculated to try and make predictions about the survivors in our validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.788466Z","iopub.status.busy":"2023-12-15T18:36:22.788155Z","iopub.status.idle":"2023-12-15T18:36:22.814972Z","shell.execute_reply":"2023-12-15T18:36:22.813815Z","shell.execute_reply.started":"2023-12-15T18:36:22.788438Z"},"trusted":true},"outputs":[],"source":["serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.819159Z","iopub.status.busy":"2023-12-15T18:36:22.816741Z","iopub.status.idle":"2023-12-15T18:36:22.864182Z","shell.execute_reply":"2023-12-15T18:36:22.862846Z","shell.execute_reply.started":"2023-12-15T18:36:22.819120Z"},"trusted":true},"outputs":[],"source":["def estimate_missing_ages(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    mean_age = old_df[\"Age\"].mean()\n","    new_df[\"Age\"].fillna(value=mean_age, inplace=True)\n","    return new_df\n","\n","def estimate_missing_fares(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df[\"Fare\"].fillna(value=0, inplace=True)\n","    return new_df\n","    \n","def prepare_data(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df = remove_irrelevant_data(new_df)\n","    new_df = estimate_missing_ages(new_df)\n","    new_df = estimate_missing_fares(new_df)\n","    print(\"Searching for NA values:\")\n","    print(new_df.isna().any())\n","    new_df = convert_ticket_class_to_binary_values(new_df)\n","    new_df = convert_embarkation_port_to_binary_values(new_df)\n","    new_df = convert_sex_to_binary_value(new_df)\n","    new_df = convert_numeric_column_to_decimal(new_df, \"Age\")\n","    new_df = convert_numeric_column_to_decimal_with_logarithm(new_df, \"Fare\")\n","    new_df[\"Constant\"] = 1\n","    return new_df\n","    \n","serving_df = prepare_data(serving_df)\n","assert (input_df.columns == serving_df.columns).all()\n","serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.866861Z","iopub.status.busy":"2023-12-15T18:36:22.866374Z","iopub.status.idle":"2023-12-15T18:36:22.890775Z","shell.execute_reply":"2023-12-15T18:36:22.889549Z","shell.execute_reply.started":"2023-12-15T18:36:22.866818Z"},"trusted":true},"outputs":[],"source":["def create_predictions(validation_df: pd.DataFrame, optimized_weights: np.array) -> np.array:\n","    return np.dot(validation_df.to_numpy(), optimized_weights)\n","\n","serving_df[\"Survival Prediction\"] = create_predictions(serving_df, nn_params)\n","serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
