{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-15T18:36:11.577650Z","iopub.status.busy":"2023-12-15T18:36:11.576570Z","iopub.status.idle":"2023-12-15T18:36:11.587718Z","shell.execute_reply":"2023-12-15T18:36:11.586441Z","shell.execute_reply.started":"2023-12-15T18:36:11.577565Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on Kaggle: False\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","\n","is_kaggle = \"KAGGLE_WORKING_DIR\" in os.environ or \"/kaggle\" in os.getcwd()\n","print(\"Running on Kaggle:\", is_kaggle)\n","\n","if is_kaggle:\n","    data_path = \"/kaggle/input/titanic/\"\n","else:\n","    data_path = os.getcwd() + \"/\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","np.set_printoptions(linewidth=140)\n","torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n","pd.set_option('display.width', 140)"]},{"cell_type":"markdown","metadata":{},"source":["Based on fast.ai chapter 5 we'll now iterate on the numpy-titanic notebook by using pytorch and applying some best practices from that chapter"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Data set"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.590356Z","iopub.status.busy":"2023-12-15T18:36:11.590031Z","iopub.status.idle":"2023-12-15T18:36:11.627922Z","shell.execute_reply":"2023-12-15T18:36:11.626658Z","shell.execute_reply.started":"2023-12-15T18:36:11.590329Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n","0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n","1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n","2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n","3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n","4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n","..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n","886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n","887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n","888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n","889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n","890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n","\n","        Fare Cabin Embarked  \n","0     7.2500   NaN        S  \n","1    71.2833   C85        C  \n","2     7.9250   NaN        S  \n","3    53.1000  C123        S  \n","4     8.0500   NaN        S  \n","..       ...   ...      ...  \n","886  13.0000   NaN        S  \n","887  30.0000   B42        S  \n","888  23.4500   NaN        S  \n","889  30.0000  C148        C  \n","890   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(data_path + \"train.csv\")\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### Handling na values\n","For linear regression to work we need numerical values, n/a values are not numerical so we should check if our data set contain them."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We should avoid removing columns or rows. Even the absence of data can sometimes indicate a pattern.\n","\n","There are many ways to substitute na_values, the easiest of which is to replace na values with the mode value (the most commonly occuring value). This is a good starting point as usually the method of substituion doesn't have a large impact on our results so the mode is good to get an MVP up and running we can iterate on."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId                      1\n","Survived                       0.0\n","Pclass                         3.0\n","Name           Abbing, Mr. Anthony\n","Sex                           male\n","Age                           24.0\n","SibSp                          0.0\n","Parch                          0.0\n","Ticket                        1601\n","Fare                          8.05\n","Cabin                      B96 B98\n","Embarked                         S\n","Name: 0, dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["modes = df.mode().iloc[0]\n","modes"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Embarked       0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.fillna(modes, inplace=True)\n","df.isna().sum()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def substitue_na_with_modes(df: pd.DataFrame) -> pd.DataFrame:\n","    modes = df.mode().iloc[0]\n","    return df.fillna(modes)"]},{"cell_type":"markdown","metadata":{},"source":["### Converting Category Data to Binary Categorical Values\n"]},{"cell_type":"markdown","metadata":{},"source":["We can get view our non-numeric or numberic data using the describe function.\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Ticket</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>891</td>\n","      <td>2</td>\n","      <td>681</td>\n","      <td>147</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>347082</td>\n","      <td>B96 B98</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>577</td>\n","      <td>7</td>\n","      <td>691</td>\n","      <td>646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Name   Sex  Ticket    Cabin Embarked\n","count                       891   891     891      891      891\n","unique                      891     2     681      147        3\n","top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n","freq                          1   577       7      691      646"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=object)"]},{"cell_type":"markdown","metadata":{},"source":["Sex and Embarked only have 2, and 3 unique values respectively. It's safe to say these are categorical values.\n","\n","We should also check if any of our numbers are categorical"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>28.566970</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.199572</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n","count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n","mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n","std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n","min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n","25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n","50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n","75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n","max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=(np.number))"]},{"cell_type":"markdown","metadata":{},"source":["We can see from its quarile values that PClass is likely also categorical despite being numeric as its only values are 1, 2 or 3. We can confirm this by looking at the [data dictionary](https://www.kaggle.com/competitions/titanic/data) for the kaggle competition and by via pandas.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([3, 1, 2])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.Pclass.unique()"]},{"cell_type":"markdown","metadata":{},"source":["\n","Sex, the Passenger class and Embarking city are not measurable attributes so we should convert them to Boolean numbers that can be used as co-efficients. In the previous notebook we did this manually however this pandas can do this for us using `Dataframe.get_dummies()`"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.664903Z","iopub.status.busy":"2023-12-15T18:36:11.664551Z","iopub.status.idle":"2023-12-15T18:36:11.691977Z","shell.execute_reply":"2023-12-15T18:36:11.690666Z","shell.execute_reply.started":"2023-12-15T18:36:11.664869Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Embarked_C',\n","       'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3'],\n","      dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","df = pd.get_dummies(df, columns=categorical_feature_names, dtype=int)\n","df.columns"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0         1           0         0         0         1           0           0           1\n","1         0           1         1         0         0           1           0           0\n","2         0           1         0         0         1           0           0           1\n","3         0           1         1         0         0           0           0           1\n","4         1           0         0         0         1           0           0           1"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["dummy_column_names = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q',\n","       'Embarked_S']\n","df[dummy_column_names].head()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def convert_categories_to_binary_values(df: pd.DataFrame) -> pd.DataFrame:\n","    categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","    return pd.get_dummies(df, columns=categorical_feature_names, dtype=int)"]},{"cell_type":"markdown","metadata":{},"source":["### Handling long-tail numerical data"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib\n","df.Fare.hist()"]},{"cell_type":"markdown","metadata":{},"source":["The `Fare` column has lots of small values with the occasional very large value. Uniform normalization using the max value isn't ideal when we're dealing with lots of small values with occasional very large values as the variation between the lower numbers will be lost. To normalize the values we can use a log function (log10 here) to bring the numbers down to reasonable ranges. We must use `log10(x+1)` to avoid 0 values as `log10(0)` would give us infinity."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.771533Z","iopub.status.busy":"2023-12-15T18:36:11.771187Z","iopub.status.idle":"2023-12-15T18:36:11.795392Z","shell.execute_reply":"2023-12-15T18:36:11.794544Z","shell.execute_reply.started":"2023-12-15T18:36:11.771504Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import math\n","df['LogFare'] = np.log(df['Fare'] + 1)\n","df.LogFare.hist()"]},{"cell_type":"markdown","metadata":{},"source":["## Linear Regression"]},{"cell_type":"markdown","metadata":{},"source":["### Pytorch Tensors\n","For our gradient descent we'll be using Pytorch rather than numpy for this workbook as it will do a lot of the heavy lifting for us. Alongside Tensorflow pytorch is the most commonly used framework for machine learning."]},{"cell_type":"markdown","metadata":{},"source":["We'll start by creating Tensors for our target values (known survival status) and features (our numerical data)."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n","        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n","        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n","        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n","        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n","        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n","        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n","        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n","        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n","        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n","        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from torch import tensor\n","target_tensor = tensor(df.Survived)\n","target_tensor"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>LogFare</th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2.110213</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4.280593</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.188856</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3.990834</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.202765</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.639057</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.433987</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>24.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3.196630</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.433987</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.169054</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["      Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0    22.0      1      0  2.110213         1           0         0         0         1           0           0           1\n","1    38.0      1      0  4.280593         0           1         1         0         0           1           0           0\n","2    26.0      0      0  2.188856         0           1         0         0         1           0           0           1\n","3    35.0      1      0  3.990834         0           1         1         0         0           0           0           1\n","4    35.0      0      0  2.202765         1           0         0         0         1           0           0           1\n","..    ...    ...    ...       ...       ...         ...       ...       ...       ...         ...         ...         ...\n","886  27.0      0      0  2.639057         1           0         0         1         0           0           0           1\n","887  19.0      0      0  3.433987         0           1         1         0         0           0           0           1\n","888  24.0      1      2  3.196630         0           1         0         0         1           0           0           1\n","889  26.0      0      0  3.433987         1           0         1         0         0           1           0           0\n","890  32.0      0      0  2.169054         1           0         0         0         1           0           1           0\n","\n","[891 rows x 12 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["feature_names = ['Age', 'SibSp', 'Parch', 'LogFare'] + dummy_column_names\n","feature_df = df[feature_names]\n","feature_df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        ...,\n","        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["features = feature_df.values\n","feature_tensor = tensor(features, dtype=torch.float)\n","feature_tensor"]},{"cell_type":"markdown","metadata":{},"source":["### Normalization\n","Once all our features are numerical we need to ensure they're somewhat uniform. For Linear regression and many other ML methods having some features be much larger than others will disrupt the process. Rather than do this manually we can have Pytorch do this for us."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([80.0000,  8.0000,  6.0000,  6.2409,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["max_values, max_indices = feature_tensor.max(dim=0)\n","max_values"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.0000, 0.0000, 0.3600, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.6750, 0.0000, 0.0000, 0.6358, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        ...,\n","        [0.3125, 0.0000, 0.0000, 0.3342, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4875, 0.0000, 0.8333, 0.5456, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.3375, 0.0000, 0.0000, 0.4229, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.2375, 0.0000, 0.0000, 0.5502, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.1250, 0.3333, 0.5122, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3250, 0.0000, 0.0000, 0.5502, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.4000, 0.0000, 0.0000, 0.3476, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["feature_tensor = feature_tensor / max_values\n","feature_tensor"]},{"cell_type":"markdown","metadata":{},"source":["#### Broadcasting\n","`feature_tensor / max_values` is an example of [broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html). \n","`max_values` is a one dimensional vector with shape (12). `feature_tensor` is a 2 dimensional matrix with shape (892,12). Because `max_values` is the same size as one of `feature_tensor`'s it will be applied to all 891 rows of `feature_tensor`\n","\n","Broadcasting is useful for large datasets. The calculations are optimized and run on a GPU when available."]},{"cell_type":"markdown","metadata":{},"source":["### Prepare initial linear co-efficient values\n","For linear regression we'd like a one dimensional vector of coefficients equal to our number of rows. Unlike in previous examples we don't need a constant as our dummy variables effectively act as a constant."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.820322Z","iopub.status.busy":"2023-12-15T18:36:11.819991Z","iopub.status.idle":"2023-12-15T18:36:11.833908Z","shell.execute_reply":"2023-12-15T18:36:11.832743Z","shell.execute_reply.started":"2023-12-15T18:36:11.820295Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(442)\n","coefficient_count = feature_tensor.shape[1]\n","coefficients = torch.rand(coefficient_count) - 0.5\n","coefficients"]},{"cell_type":"markdown","metadata":{},"source":["Generally we don't want to set a manual seed so we can be aware of how stable our data is or isn't. However for the sake of this lesson I'd like to check I'm getting consistent results with the lesson plan."]},{"cell_type":"markdown","metadata":{},"source":["### Create Predictions\n","We calculate the linear function of our parameters by multiplied them against our random Coefficients then summing each row of weighted values up to create a prediction for each passenger\n","Pytorch's broadcasting can once again be used here to simplify things considerably. We'll print it out to check there aren't any weighted values that are significantly oversized."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.836343Z","iopub.status.busy":"2023-12-15T18:36:11.835997Z","iopub.status.idle":"2023-12-15T18:36:11.858845Z","shell.execute_reply":"2023-12-15T18:36:11.857637Z","shell.execute_reply.started":"2023-12-15T18:36:11.836315Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n","        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["weighted_values = feature_tensor * coefficients\n","weighted_values[:4]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["predictions = weighted_values.sum(dim=1)\n","predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate loss\n","Our loss here is the average difference between our prediction value and whether the passegner survived or not (1 or 0)."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["loss = torch.abs(predictions - target_tensor).mean()\n","loss"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def calculate_loss(features: torch.Tensor, coefficients: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    return torch.abs(predictions - targets).mean()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    return (coefficients * features).sum(axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Doing a single Gradient Descent step\n","Now we want to optimize our loss with gradient descent. This too will be significantly easier using Pytorch as it will calculate the gradient for us.\n","\n","We must tell pytorch to store the results of each coefficient calculation so we can get the gradients from it later."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.860841Z","iopub.status.busy":"2023-12-15T18:36:11.860409Z","iopub.status.idle":"2023-12-15T18:36:22.655866Z","shell.execute_reply":"2023-12-15T18:36:22.654577Z","shell.execute_reply.started":"2023-12-15T18:36:11.860799Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["coefficients.requires_grad_()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382, grad_fn=<MeanBackward0>)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss"]},{"cell_type":"markdown","metadata":{},"source":["The loss is in a tensor where can ask Pytorch to calculate the gradient by calling `backward()`"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["loss.backward()\n","coefficients.grad"]},{"cell_type":"markdown","metadata":{},"source":["Here we perform one gradient descent step\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.5197)\n"]}],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss.backward\n","with torch.no_grad():\n","    coefficients.sub_(coefficients.grad * 0.1)\n","    coefficients.grad.zero_()\n","    print(calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor))"]},{"cell_type":"markdown","metadata":{},"source":["A few points:\n","1. `torch.no_grad()` is required to ensure the parameter update step is peformed without tracking gradients. We want to track gradients for the forward and backward steps but not when directly modifying the parameters\n","2. `coefficients.sub_(coefficients.grad * 0.1)` reduces the coefficients by their gradient to the loss. More significant features will be reduced more. \n","3. Both `sub_` and `zero_` operations are done in place for memory efficiency and to preserve the tensors memory graph (this is also ensured by `torch.no_grad()` although it's good practice when working with tensors).\n","4. `coefficients.grad.zero_()` sets our gradients to zero. This is necessary as if we were to do another backpass the new gradients would be added to the old ones."]},{"cell_type":"markdown","metadata":{},"source":["### Creating a validation set\n"]},{"cell_type":"markdown","metadata":{},"source":["Before we begin training we need a validation set to compare our training data against."]},{"cell_type":"markdown","metadata":{},"source":["I've deviated from the [fast.ai kaggle workbook](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch) as they split their validation set using the fastai library to keep things consistent for their next chapter. I'm interested in primarily learning Pytorch so I'm going to split the dataset without the fastai library. However so I can check if my results match fast.ai's I'm going to include their splitter here it will be used if `use_fastai_splitter` is set to `True` so I can check my results are consistent with the fast.ai tutorials."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["from numpy import int64\n","from fastai.data.transforms import RandomSplitter\n","\n","def split_data_with_fastai(df: pd.DataFrame) -> tuple[np.int64, np.int64]:\n","    return RandomSplitter(seed=42)(df)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["First we'll split our data"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["(713, 178)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["use_fastai_splitter = True\n","total_passengers = feature_tensor.size(0)\n","training_set_size = int(total_passengers * 0.8)\n","\n","if use_fastai_splitter:\n","    train_indices, validation_indices = split_data_with_fastai(df)\n","else:\n","    randomized_indices = torch.randperm(total_passengers)\n","    train_indices = randomized_indices[:training_set_size]\n","    validation_indices = randomized_indices[training_set_size:]\n","\n","training_features = feature_tensor[train_indices]\n","validation_features = feature_tensor[validation_indices]\n","training_targets = target_tensor[train_indices]\n","validation_targets = target_tensor[validation_indices]\n","len(training_features), len(validation_features)"]},{"cell_type":"markdown","metadata":{},"source":["This note book doesn't use Pytorch's `Dataset`s. We'd likely use these in a real project although for this example we're keeping things a bit barer than normal so we can see the process."]},{"cell_type":"markdown","metadata":{},"source":["We'll add what we've done so far in to functions to make things easier to read and re-usable."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["def update_coefficients(coefficients: torch.Tensor, learning_rate):\n","    coefficients.sub_(coefficients.grad * learning_rate)\n","    coefficients.grad.zero_()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def one_epoch(coefficients, learning_rate):\n","    loss = calculate_loss(training_features, coefficients, training_targets)\n","    loss.backward()\n","    with torch.no_grad():\n","        update_coefficients(coefficients, learning_rate=learning_rate)\n","        \n","    print(f\"{loss:.3f}\", end=\"; \")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def generate_coefficients(features: torch.Tensor) -> torch.Tensor:\n","    coefficient_count = features.shape[1]\n","    coefficients = torch.rand(coefficient_count) - 0.5\n","    coefficients.requires_grad_()\n","    return coefficients"]},{"cell_type":"markdown","metadata":{},"source":["Now to train the model"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def train_model(epoch_count=30, learning_rate=0.1):\n","    coefficients = generate_coefficients(training_features)\n","    for i in range(epoch_count):\n","        one_epoch(coefficients, learning_rate=learning_rate)\n","    return coefficients"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.550; 0.494; 0.446; 0.400; 0.385; 0.392; 0.348; 0.351; 0.365; 0.327; 0.345; 0.310; 0.326; 0.292; 0.308; 0.280; 0.323; 0.269; "]},{"data":{"text/plain":["tensor([ 0.0114, -0.1277, -0.0490,  0.2052,  0.0136,  0.7174,  0.0278, -0.1602, -0.1642,  0.1394,  0.3767,  0.2155], requires_grad=True)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["coefficients = train_model(epoch_count=18, learning_rate=0.2)\n","coefficients"]},{"cell_type":"markdown","metadata":{},"source":["We can see below that our models has optimized our weights to reduce our loss. From this we can see that the model believes"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature</th>\n","      <th>Coefficient</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Age</td>\n","      <td>0.011448</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SibSp</td>\n","      <td>-0.127748</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Parch</td>\n","      <td>-0.049038</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LogFare</td>\n","      <td>0.205193</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sex_male</td>\n","      <td>0.013623</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sex_female</td>\n","      <td>0.717442</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Pclass_1</td>\n","      <td>0.027782</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Pclass_2</td>\n","      <td>-0.160171</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Pclass_3</td>\n","      <td>-0.164208</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Embarked_C</td>\n","      <td>0.139427</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Embarked_Q</td>\n","      <td>0.376680</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Embarked_S</td>\n","      <td>0.215454</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Feature  Coefficient\n","0          Age     0.011448\n","1        SibSp    -0.127748\n","2        Parch    -0.049038\n","3      LogFare     0.205193\n","4     Sex_male     0.013623\n","5   Sex_female     0.717442\n","6     Pclass_1     0.027782\n","7     Pclass_2    -0.160171\n","8     Pclass_3    -0.164208\n","9   Embarked_C     0.139427\n","10  Embarked_Q     0.376680\n","11  Embarked_S     0.215454"]},"metadata":{},"output_type":"display_data"}],"source":["def show_coeffs(): \n","    coeff_array = [coeff.item() for coeff in coefficients]\n","    coeff_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coeff_array})\n","    display(coeff_df)\n","show_coeffs()"]},{"cell_type":"markdown","metadata":{},"source":["### Measuring accuracy"]},{"cell_type":"markdown","metadata":{},"source":["To view our accuracy we'll now use our validation set. We'll create predictions using our newly trained coefficients and see how accurate they are."]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1.0226, 0.3008, 0.0616, 0.2132, 0.1593, 0.1594, 0.7728, 0.8635, 0.0960, 0.7756], grad_fn=<SliceBackward0>)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["predictions = create_predictions(validation_features, coefficients=coefficients)\n","predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["If our predictions is >0.5 and the passegner surivied we're correct. If the passenger died we want a prediction < 0.5. 0 = died, 1 = survived. This code merely rounds our predictions to whichever of these values is closest"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.7865)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["results = validation_targets.bool() == (predictions>0.5)\n","results.float().mean()"]},{"cell_type":"markdown","metadata":{},"source":["We're 79% accurate which is pretty good going."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["from torch import Tensor\n","\n","\n","def calculate_accuracy(coefficients, features: torch.Tensor) -> float:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    results = validation_targets.bool() == (predictions>0.5)\n","    return results.float().mean()"]},{"cell_type":"markdown","metadata":{},"source":["### Sigmoid\n","When creating predictions that are between 0 and 1 we can increase our accuracy by using the sigmoid function which moves all our values between 0 and 1 and larger negative or positives values will respectively asymptotically converge towards 0 or 1."]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAnYAAAHTCAYAAACqbVU5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFQklEQVR4nO3dd3hUZcLG4WcyyUwS0ggpQAi910CAiAqCRkGRXV0LsiiIXZEPZV0Fl2LHLq6i2HVVFlbB7rIiolhQSug9QEgIpAHpZZKZ8/0RiERagCRnMvO7r2uuJGfOYZ5xZPJw3jnvazEMwxAAAAAaPB+zAwAAAKB2UOwAAAA8BMUOAADAQ1DsAAAAPATFDgAAwENQ7AAAADwExQ4AAMBDUOwAeDzDMJSfny+m7QTg6Sh2ADxeQUGBQkNDVVBQYHYUAKhTFDsAAAAPQbEDAADwEBQ7AAAAD0GxAwAA8BAUOwAAAA9BsQMAAPAQFDsAAAAPQbEDAADwEBQ7AAAAD0GxAwAA8BAUOwAAAA9BsQMAAPAQFDsAAAAPQbEDAADwEBQ7AAAAD0GxA1Cvli1bphEjRqh58+ayWCz69NNPT3nM999/rz59+shut6t9+/Z699136zwnADREFDsA9aqoqEi9evXS7Nmza7T/7t27NXz4cA0ZMkRr167VPffco1tuuUX/+9//6jgpADQ8FsMwDLNDAPBOFotFn3zyia644ooT7vPAAw/oq6++0saNG6u2XXfddcrNzdWiRYtq9Dj5+fkKDQ1VXl6eQkJCzjY2ALgtztgBcGvLly9XYmJitW1Dhw7V8uXLT3hMWVmZ8vPzq90AwBtQ7AC4tYyMDEVHR1fbFh0drfz8fJWUlBz3mJkzZyo0NLTqFhsbWx9RAcB0vmYHAIDaNmXKFE2aNKnq5/z8fModAFOVljuVX1qugtIKFZc5VeSoUImj8muxw6nisgoVlzv/cJ9TJY4KFZU59e/bzqnR41DsALi1pk2bKjMzs9q2zMxMhYSEKCAg4LjH2O122e32+ogHwEs4KlwqKC1XfmmF8kvKlVdSrvzScuWXVBz+emRb5f1HtuWXViivpFyOCle95KTYAXBrAwYM0Ndff11t2+LFizVgwACTEgFo6JwuQ4eKHTpQ6FBOYdnhm0MHDn9/oNBRVdzySirLW0m586wf12KRguy+amTzVaDdqkY2XwXYrGpksyrQ5qtAm1WN7L9vC7D5Hv5qrfFjUOwA1KvCwkIlJydX/bx7926tXbtW4eHhatmypaZMmaL09HT961//kiTdcccdevnll3X//ffrpptu0nfffaf//Oc/+uqrr8x6CgDcUFmFs6qoHSh0KPvw15yjytqRAnewqEyuM5wTJNjuq5AAPwX7+yo0wE8hAX4K8fdTSIDv4a9+CvGv3Cf06PsC/BRk85WPj6V2n/gfUOwA1KtVq1ZpyJAhVT8f+Szc2LFj9e6772r//v1KTU2tur9Nmzb66quvdO+99+rFF19UixYt9Oabb2ro0KH1nh2AOQzDUE6hQ/tyS5SeW1L1Nf1QifblVX49VFx+2n9ueCObmjSyKSLIriZBlV8jg+1q0simsMDfS9uRghbk7ytrHRezs8U8dgA8HvPYAe6trMKp/bml2pdbor2Hi9vvJa5U6bklNfqMmq+PpaqgHSlrkUd9f2R7RJBN4Y1s8rV63uQgnLEDAAB1zjAMZeaXKTmrUDuyCg5/LdTunCJlF5Sd8niLRYoO9lfzMH81DwtQTOMAxYQFqHlo5fdNQ/wVFugni8W9z6jVNYodAACoNS6Xob2HSpScXaAdmYVVBW5nVqEKyipOeJy/n09lUQsLUIvGlYXt6AIXHeIvm6/nnWGrbRQ7AABw2sqdLu05UFRZ3DILlZxd+XVXTqFKy48/bGr1sahVk0C1jwxSh+ggtY8KUrvIILVoHKjGnG2rFRQ7AABwQoZhKOVAsdbvzVVy1u9n4FJyilRxgktLbb4+ahvRSO2jgtQhKrjya3SQWjUJlN235lN34PRR7AAAQJXCsgqtT8tVUuohJaXmak3qoRNecRpos6pDVJDaHV3gooIUGx7o9lePeiqKHQAAXsowDO3KKdKa1MNFbs8hbc8sOGaON5uvj7o1D1HnpsFqFxmkDtHB6hAVpGah/gyfuhmKHQAAXqKgtFzr0vKUlHpIa1IPaU1arnKPczYuJixAvVuGqU/LxurdMkxdm4cwhNpAUOwAAPBAR87Grd5TWeKS9uRqe1aB/jh7rc3XRz1jQtWnVWP1aRmm3i0bKzrE35zQOGsUOwAAPESxo0K/JB/Q0m1Z+n5bttJzS47ZJyYsoFqJ69oshGlEPAjFDgCABiwlp0hLt2Vp6bZs/brrQLUVGmy+PurVIvTwkGplmYvibJxHo9gBANCAlJY7tWL3waqzcrtziqrdHxMWoAs7R2lwp0gNaNdEgTZ+1XsTXm0AANxcem6Jlm7N0vfbsvRz8gGVlDur7vP1sahf63AN6RypCztHqV1kEFeqejGKHQAAbsblMrQy5aC+25qlpduytD2zsNr9UcF2DekUpSGdI3Ve+wgF+/uZlBTuhmIHAICb2JVdqIVJ6fpkTXq1Cx98LFKflo015PAQa9dmIZyVw3FR7AAAMFFecbm+WL9PC5P2Kik1t2p7sN1XiV2jNaRzlAZ1iFBYoM28kGgwKHYAANSzcqdLy7Zna0HSXn27OUsOZ+WVrD4WaVDHSF3Vp4Uu7hotfz8mBcbpodgBAFAPDMPQpn35WpiUrs/XpSun0FF1X+emwbqqTwv9uXdzRQUzHQnOHMUOAIA6lJVfqk/XpmthUrq2ZhRUbY8IsunPcTH6S58YdWseamJCeBKKHQAAtay03KlvNmdqweq9+nFHtlyHl/Gy+fro4q7RuqpPjAZ2iJSflRUfULsodgAA1JK8knJ98Osevf3Tbh0o+n2oNb5VY13Vp4WG92im0ECmJkHdodgBAHCWsgvK9PbPu/XB8j0qKKuQVLkCxFV9YnRlnxZqE9HI5ITwFhQ7AADO0N5DxXp92S7NX5mmssNrtHaMDtJdg9vr8p7N5MtQK+oZxQ4AgNOUnFWgV77fqc/X7lPF4Q/QxcWGafyQ9rqoc5R8fJg8GOag2AEAUEPr0nL1yvfJ+mZzpozDF0Sc3z5Cdw1ppwFtm7AaBExHsQMA4CQMw9DyXQf0ytKd+ik5p2r70G7Rumtwe/WKDTMvHPAHFDsAAI7D5TK0ZGuWZi9N1tq0XEmS1ceiP8c1150XtFOH6GBzAwLHQbEDAOAoFU6Xvly/X698n6ztmYWSJLuvj0b2i9WtA9sqNjzQ5ITAiVHsAABQ5aTCH6/eq9eW7VTawRJJUpDdVzcMaKWbzmujyGC7yQmBU6PYAQC8mmEY+u/GDD365WbtzyuVJIU3sunm89vo+nNaKTSACYXRcFDsAABea2d2oR76fJN+3FF5UUSzUH/dPqitRvZrqQCb1eR0wOmj2AEAvE6xo0Kzlybr9WW7VO40ZPP10R0XtNNdg9vJ349Ch4aLYgcA8BqGYeh/mzL16JeblZ5b+Tm6wZ0i9dCIbmrNsl/wABQ7AIBXSMkp0kNfbNL327IlVa7lOn1EV13SNZqJheExKHYAAI9WWu7UK0uTNeeHXXI4XbJZfXTboLYaP6Q9n6ODx6HYAQA81rebM/XQF5u091DlsOvADhF6+E/d1DYyyORkQN2g2AEAPE7awWI9/MUmfbslS1Ll1a7TL++qYd2bMuwKj0axAwB4jNJyp177YZde+T5ZZRUu+fpYdMvAtvq/i9or0MavPHg+/i8HAHiEpduy9NDnm7TnQLEk6dx2TfTIn7upfRRrusJ7UOwAAA1afmm5Hly4QV+u3y9Jig6xa9rlXTW8RzOGXeF1KHYAgAZrY3qexs9N0p4DxfL1seim89vo/y7qoCA7v97gnfg/HwDQ4BiGoQ9/S9UjX2yWw+lSTFiAZo/uo7jYMLOjAaai2AEAGpTCsgpNWbhBX6zbJ0lK7BKlZ6/ppbBAm8nJAPNR7AAADcaW/fka/2GSduUUydfHogeGddYtA9vwWTrgMIodAMDtGYah+SvTNOPzTSqrcKlZqL9e/msfxbdqbHY0wK1Q7AAAbq3YUaGpn2zUwjXpkqTBnSL1/LVxCm/E0CvwRxQ7AIDb2p5ZoLs+TFJyVqGsPhb97ZKOumNQO/n4MPQKHA/FDgDglj5evVdTP92g0nKXooLtemlUbyW0bWJ2LMCtUewAAG6lxOHU9M826qPVeyVJAztE6IWRcYoIspucDHB/FDsAgNtIzirU+A+TtC2zQD4W6d7Ejho/pD1Dr0ANUewAAG7hs7XpmrJwg4odTkUE2fXPUXE6t12E2bGABoViBwAwVWm5Uw9/sVn/XpEqSRrQtoleHBWnqGB/k5MBDQ/FDgBgmt05RbrrwyRt2Z8vi0WaMKS9JiZ2lJWhV+CMUOwAAKb4cv0+TV6wQYVlFWrSyKYXRsZpUMdIs2MBDRrFDgBQrwzD0MvfJeu5xdslSf1bh+ufo3qraShDr8DZotgBAOqNYRh64usteuPH3ZKk2we11d+HdpKv1cfkZIBnoNgBAOqF02XowYUbNH9VmiRp2uVddfP5bUxOBXgWih0AoM45Kly6d/5afbVhv3ws0pNX9dS1fWPNjgV4HIodAKBOFTsqdMcHSVq2PVs2q4/+OSpOw7o3MzsW4JEodgCAOpNXUq6b312pVXsOKcDPqtfHxGtgB658BeoKxQ4AUCdyCss05q0V2rw/XyH+vnpnXD/Ftwo3Oxbg0Sh2AIBal55bohve/E27cooUEWTTv25KUNfmIWbHAjwexQ4AUKt2ZRfq+jd/0768UsWEBeiDWxLUJqKR2bEAr0CxAwDUmk378jTmrRU6UORQ28hG+uDmBDUPCzA7FuA1KHYAgFqxKuWgxr27UgWlFeoeE6L3xvVXkyC72bEAr0KxAwCctR+2Z+v291eptNyl/q3D9eaNfRXi72d2LMDrUOwAAGfl6w37NXHeGpU7DQ3uFKlXR8crwGY1OxbglVicD0C9mz17tlq3bi1/f38lJCRoxYoVJ91/1qxZ6tSpkwICAhQbG6t7771XpaWl9ZQWJzN/Zarunpukcqehy3s20+s39KXUASai2AGoV/Pnz9ekSZM0Y8YMJSUlqVevXho6dKiysrKOu//cuXM1efJkzZgxQ1u2bNFbb72l+fPn68EHH6zn5PijN3/cpQcWbJDLkEb1b6kXr+stmy+/VgAzWQzDMMwOAcB7JCQkqF+/fnr55ZclSS6XS7GxsZowYYImT558zP533323tmzZoiVLllRt+9vf/qbffvtNP/30U40eMz8/X6GhocrLy1NICHOpnS3DMPT84u166btkSdLtF7TV5GGdZbFYTE4GgH9aAag3DodDq1evVmJiYtU2Hx8fJSYmavny5cc95txzz9Xq1aurhmt37dqlr7/+WpdddtkJH6esrEz5+fnVbqgdLpehhz7fVFXq7h/WSVMu7UKpA9wEF08AqDc5OTlyOp2Kjo6utj06Olpbt2497jF//etflZOTo/PPP1+GYaiiokJ33HHHSYdiZ86cqYcffrhWs0OqcLp0/8frtXBNuiwW6ZE/d9cN57QyOxaAo3DGDoBb+/777/XEE0/olVdeUVJSkhYuXKivvvpKjz766AmPmTJlivLy8qpuaWlp9ZjYM7lcRlWps/pYNGtkHKUOcEOcsQNQbyIiImS1WpWZmVlte2Zmppo2bXrcY6ZNm6YbbrhBt9xyiySpR48eKioq0m233aZ//OMf8vE59t+ndrtddjsT49ampxZt1cI16fL1sejV6+N1cdfoUx8EoN5xxg5AvbHZbIqPj692IYTL5dKSJUs0YMCA4x5TXFx8THmzWiun0+Dar/rx5o+79NqyXZKkp67qSakD3Bhn7ADUq0mTJmns2LHq27ev+vfvr1mzZqmoqEjjxo2TJI0ZM0YxMTGaOXOmJGnEiBF6/vnn1bt3byUkJCg5OVnTpk3TiBEjqgoe6s5na9P12FdbJEkPDOusq+JbmJwIwMlQ7ADUq5EjRyo7O1vTp09XRkaG4uLitGjRoqoLKlJTU6udoZs6daosFoumTp2q9PR0RUZGasSIEXr88cfNegpe46cdObrvo3WSpHHntdYdF7Q1ORGAU2EeOwAej3nsTt/G9DyNfG25ihxOXd6zmf55XW/5+DClCeDu+IwdAKCaPQeKdOM7K1TkcOrcdk303LW9KHVAA0GxAwBUySks09i3Vyin0KGuzUL02g3xsvvyWUagoaDYAQAkSYVlFRr3zkqlHChWbHiA3r2pn4L9/cyOBeA0UOwAAHJUuHTnB6u1IT1P4Y1sem9cf0UF+5sdC8BpotgBgJerXFVinX7ckaMAP6veubGf2kYGmR0LwBmg2AGAl3ty0VZ9unbf4VUl+qhXbJjZkQCcIYodAHixN3/cpdcPryrx9NU9NbhTlMmJAJwNih0AeKmjV5WYfGln/aUPq0oADR3FDgC80I87sqtWlbjpvDa6fRCrSgCegGIHAF5mw9483fH+apU7DY3o1VxTh3eRxcIExIAnoNgBgBfZc6BI496tXFXivPZN9Ow1PVlVAvAgFDsA8BLZBWUac9SqEnOuZ1UJwNNQ7ADACzgqXLr9/VXaw6oSgEej2AGAF3jsq81KSs1ViL8vq0oAHoxiBwAebmHSXv1r+R5J0qzr4lhVAvBgFDsA8GCb9uVpysINkqT/u6iDLuwcbXIiAHWJYgcAHiqvuFx3fpCksgqXLugYqYkXdTA7EoA6RrEDAA/kchm6Z/4apR4sVovGAXrxujhZmdYE8HgUOwDwQC99l6yl27Jl9/XRnOvjFRZoMzsSgHpAsQMAD7N0W5ZmLdkuSXr8yh7qHhNqciIA9YViBwAeJPVAse6Zt1aGIY1OaKmr41uYHQlAPaLYAYCHKC136o4PViuvpFxxsWGaPqKr2ZEA1DOKHQB4AMMw9I9PNmrz/nw1aWTTq9f3YbkwwAtR7ADAA3z4W6oWJO2Vj0V6aVRvNQsNMDsSABNQ7ACggVuTekgPf7FJknT/sM46t32EyYkAmIViBwANWE5hme78IEnlTkPDujXV7YPamh0JgIkodgDQQFU4XZowd40y8kvVNrKRnrmmpywWJiEGvBnFDgAaqGf+t03Ldx1QoM2q166PV7C/n9mRAJiMYgcADdB/N+zXa8t2SZKeubqXOkQHm5wIgDug2AFAA5OcVaj7PlonSbp1YBsN79nM5EQA3AXFDgAakMKyCt3+/ioVOZw6p224HhjW2exIANwIxQ4AGgjDMHT/x+u0M7tI0SF2vTSqj3ytvI0D+B3vCADQQLz54259vSFDflaLXhkdr8hgu9mRALgZih0ANADLdx7Qk4u2SpKmX95V8a0am5wIgDui2AGAm9ufV6K75ybJ6TL0l94xuv6cVmZHAuCmKHYA4MbKKpy668MkHShyqEuzED1+ZQ8mIQZwQhQ7AHBjzyzapjWpuQrx99Wc6/sowGY1OxIAN0axAwA39Utyjt78abck6dlreqlVk0YmJwLg7ih2AOCG8krK9bfDkxCP6h+rS7o1NTkRgIaAYgcAbmj6Zxu1P69UrZsEaurwrmbHAdBAUOwAwM18vm6fPlu7T1Yfi54fGadGdl+zIwFoICh2AOBG9uWWaOonGyRJ44e0V5+WzFcHoOYodgDgJlwuQ/d9tE75pRXq1SJUEy5sb3YkAA0MxQ4A3MTbP+/WLzsPKMDPqhdGxsmPdWABnCbeNQDADWzLKNDT/9smSfrH8C5qGxlkciIADRHFDgBMVlbh1D3z18pR4dKFnaM0OqGl2ZEANFAUOwAw2fOLt2vL/nyFN7LpyatYMgzAmaPYAYCJft11QK8v2yVJmvmXHooK9jc5EYCGjGIHACbJLy3X3/6zToYhXdu3hYayugSAs0SxAwCTPPTZJqXnlqhleKCmj+hmdhwAHoBiBwAm+Gr9fi1cky4fi/TCyF4KYnUJALWAYgcA9Swjr1QPHl5d4q7B7RXfKtzkRAA8BcUOAOqRy2Xo7x+vU15JuXrEhGpiYgezIwHwIBQ7AKhH/1qeoh935Mjfz4fVJQDUOt5RAKCe7Mgs0Mz/bpUkPXhZF7WPYnUJALWLYgcA9cBR4dI989eqrMKlQR0jdcM5rcyOBMADUewAoB7M+na7Nu3LV1ign565uierSwCoExQ7AKhjK1MOas4POyVJM6/soegQVpcAUDcodgBQhwpKy3Xv/LVyGdJVfVro0h7NzI4EwINR7ACgDj3yxWbtPVSiFo0D9NCfupodB4CHo9gBQB1ZtHG/Plq9VxaL9Py1cQr29zM7EgAPR7EDgDqQlV+qKQsrV5e444J26t+G1SUA1D2KHQDUMsMwdP+C9TpUXK5uzUN0b2JHsyMB8BIUOwCoZfNWpun7bdmy+/po1sg42Xx5qwVQP3i3AYBalJFXqie+2iJJ+vvQTuoQHWxyIgDehGIHALXEMAxN/XSDCsoqFBcbpnHntTE7EgAvQ7EDUO9mz56t1q1by9/fXwkJCVqxYsVJ98/NzdX48ePVrFkz2e12dezYUV9//XU9pa25L9fv17dbsuRntejpq3vK6sPqEgDql6/ZAQB4l/nz52vSpEmaM2eOEhISNGvWLA0dOlTbtm1TVFTUMfs7HA5dfPHFioqK0scff6yYmBjt2bNHYWFh9R/+JA4WOfTQ55skSXcP6aCODMECMIHFMAzD7BAAvEdCQoL69eunl19+WZLkcrkUGxurCRMmaPLkycfsP2fOHD3zzDPaunWr/PzObB64/Px8hYaGKi8vTyEhIWeV/0Tunb9Wn6xJV6foYH0x4XwumABgCt55ANQbh8Oh1atXKzExsWqbj4+PEhMTtXz58uMe8/nnn2vAgAEaP368oqOj1b17dz3xxBNyOp0nfJyysjLl5+dXu9WlpVuz9MmadPlYpKeu7kmpA2Aa3n0A1JucnBw5nU5FR0dX2x4dHa2MjIzjHrNr1y59/PHHcjqd+vrrrzVt2jQ999xzeuyxx074ODNnzlRoaGjVLTY2tlafx9EKSsv1j08qJyK++fw2iosNq7PHAoBTodgBcGsul0tRUVF6/fXXFR8fr5EjR+of//iH5syZc8JjpkyZory8vKpbWlpaneV7etE27csrVcvwQE26uFOdPQ4A1AQXTwCoNxEREbJarcrMzKy2PTMzU02bNj3uMc2aNZOfn5+sVmvVti5duigjI0MOh0M2m+2YY+x2u+x2e+2GP44Vuw/q/V/3SJKevKqHAmzWUxwBAHWLM3YA6o3NZlN8fLyWLFlStc3lcmnJkiUaMGDAcY8577zzlJycLJfLVbVt+/btatas2XFLXX0pLXfqgQXrJUmj+sfq3HYRpmUBgCModgDq1aRJk/TGG2/ovffe05YtW3TnnXeqqKhI48aNkySNGTNGU6ZMqdr/zjvv1MGDBzVx4kRt375dX331lZ544gmNHz/erKcgSXpxyQ7tzilSdIhdky/tYmoWADiCoVgA9WrkyJHKzs7W9OnTlZGRobi4OC1atKjqgorU1FT5+Pz+b87Y2Fj973//07333quePXsqJiZGEydO1AMPPGDWU9DG9Dy9vmyXJOmxK3ooNODMpmEBgNrGPHYAPF5tzmNX7nTpzy//rM3783V5z2Z6+a99aiklAJw9hmIB4DS8vmyXNu/PV1ignx76Uzez4wBANRQ7AKih5KxCvbhkhyRp+uVdFRFU91feAsDpoNgBQA24XIYmL1gvR4VLF3SM1JW9Y8yOBADHoNgBQA188NserdpzSI1sVj1+ZXdZLBazIwHAMSh2AHAKew8V66n/bpUkPXBpZ7VoHGhyIgA4PoodAJyEYRj6xycbVeRwqm+rxro+oZXZkQDghCh2AHASn6xJ1w/bs2Xz9dFTV/eUjw9DsADcF8UOAE4gu6BMj3y5WZI08aIOahcZZHIiADg5ih0AnMBDX2xSbnG5ujYL0W2D2podBwBOiWIHAMfxv00Z+mr9fll9LHr66p7ys/J2CcD98U4FAH+QV1KuaZ9ulCTdNqituseEmpwIAGqGYgcAfzDz6y3KKihT24hGmnhRB7PjAECNUewA4Cg/J+do3so0SdKTV/WUv5/V5EQAUHMUOwA4rNhRoSkLN0iSbjinlfq3CTc5EQCcHoodABz2/DfblXqwWM1D/XX/sE5mxwGA00axAwBJa1IP6e2fd0uSHr+yh4L9/UxOBACnj2IHwOs5Klx6YMF6uQzpyt4xGtI5yuxIAHBGKHYAvN4r3ydre2ahmjSyadrlXc2OAwBnjGIHwKttyyjQ7KXJkqSH/tRN4Y1sJicCgDNHsQPgtZwuQ/cvWK9yp6HELtG6vGczsyMBwFmh2AHwWu/8vFvr0nIVbPfVY1d0l8ViMTsSAJwVX7MDAGgYysvLlZGRoeLiYkVGRio8vGHP8ZZ2sFjPfbNdkvTg8C5qGupvciIAOHucsQNwQgUFBXr11Vd1wQUXKCQkRK1bt1aXLl0UGRmpVq1a6dZbb9XKlSvNjnnaDMPQPz7dqJJypxLahOu6frFmRwKAWkGxA3Bczz//vFq3bq133nlHiYmJ+vTTT7V27Vpt375dy5cv14wZM1RRUaFLLrlEw4YN044dO8yOXGOfrd2nZduzZfP10cy/9GAIFoDHsBiGYZgdAoD7GTVqlKZOnapu3bqddL+ysjK98847stlsuummm+op3enJz89XaGio8vLyVGH1V+LzP+hgkUP3XdJRd1/Ywex4AFBrKHYATqmgoEDBwcFmxzhjRxe7hxbt0sKkdHWKDtYXE86XzZeBCwCeg3c0AKc0cOBAZWRkmB3jrP2yM0cLk9JlsUhPXtWDUgfA4/CuBuCUevfurYSEBG3durXa9rVr1+qyyy4zKdXpe+SLzZKksQNaq3fLxianAYDaR7EDcErvvPOObrzxRp1//vn66aeftH37dl177bWKj4+X1Wo1O16N7T1Uomah/rpvaCezowBAnWAeOwA18vDDD8tut+viiy+W0+nURRddpOXLl6t///5mRzulzfvyqr5/9M/dFWTnrQ+AZ+KMHYBTyszM1MSJE/XYY4+pa9eu8vPz04033tggSl2F06WHPq8cgh3aNVqJXaNNTgQAdYdiB+CU2rRpo2XLlumjjz7S6tWrtWDBAt1222165plnzI52Su/+kqLN+/MlSZMv62xyGgCoW4xHADilt99+W9ddd13Vz8OGDdPSpUt1+eWXKyUlRbNnzzYx3YkdvWyYJEUGs2wYAM/GGTsAp3R0qTuiT58++uWXX/Tdd9+ZkOjUDMPQ1MPLhsW34gpYAN6BYgfgjLVu3Vq//PKL2TGO6/N1+/TD4WXDZvypq9lxAKBeUOwAHFdqamqN9mvcuPJsWHp6el3GOS2HihxVc9ZNGNJebSOCTE4EAPWDYgfguPr166fbb79dK1euPOE+eXl5euONN9S9e3ctWLCgHtOd3GNfbdGBIoc6RQfr9gvamR0HAOoNF08AOK7hw4crKChIF198sfz9/RUfH6/mzZvL399fhw4d0ubNm7Vp0yb16dNHTz/9tNusQPFzco4WJO2VxSI98ZfKZcNKzQ4FAPXEYhiGYXYIAO7HZrMpLS1NwcHBioyM1KhRo3TgwAGVlJQoIiJCvXv31tChQ9W9e3ezo1YpLXdq6Kxl2nOgWGMGtNIjf67Mlp+fr9DQUOXl5SkkJMTklABQdzhjB+C4mjdvrrVr12ro0KEqKSnRE088oaioKLNjndSsb3doz4FiNQ3x199ZNgyAF+IzdgCO629/+5tGjBihgQMHymKx6MMPP9TKlStVUlJidrTj2rQvT2/8uEuS9OgV3RXs72dyIgCofwzFAjih9evX64svvtC0adPUtm1bpaSkyGKxqH379urVq5fi4uLUq1cvXXrppabmdLoMXfnKz1q/N0+X9WiqV0bHV7ufoVgA3oJiB+CUOnTooOXLl6tRo0Zav3691q5dW3XbuHGjCgoKTM331k+79eiXmxXs76slky5QVEj1FSYodgC8BcUOwFkxDEMWi8W0x997qFiXvLBMxQ6nnriyh/6a0PKYfSh2ALwFn7EDcFbMLHVHlg0rdjjVv3W4rusXa1oWAHAHFDsADdbn6/bp+23Zsll99MRfesjHx7ySCQDugGIHoEE6etmwuy9sr/ZRLBsGABQ7AA3SE19XLhvWISpId7BsGABIotgBaIB+Sc7RR6srlw178qrKZcMAABQ7AA1MablTUz7ZIEm6PqGV4luFm5wIANwHxQ5Ag/Likt+XDbt/GMuGAcDRKHYAGozN+/L1+rLKZcMe+XM3lg0DgD+g2AFoEJwuQ1MWrpfTZejS7k11SbemZkcCALdDsQPQILzz826t25unYH9fPfSnbmbHAQC3RLED4PZ25xTpmf9tkyRNubSLov+wFiwAoBLFDoBbc7oM/f2jdSqrcOn89hEa1Z9lwwDgRCh2ANzau7+kaNWeQ2pks+rJq3qYujYtALg7ih0At1U5BLtVkvTg8C5q0TjQ5EQA4N4odgDckstl6P6P16m0vHII9q/9W5odCQDcHsUOgFt695cUrUypHIKd+ReGYAGgJih2ANxOSk6Rnj48BDvlsi6KDWcIFgBqgmIHwK1UDsGuV2m5S+e2a8IQLACcBoodALfy3vIUrUg5qECbVU9d1VM+PgzBAkBNUewAuI2UnCI9tYghWAA4UxQ7AG7B5TJ0/4LKIdgBbZtoNEOwAHDaKHYA3ML7v+7Rit2VQ7BPX80QLACcCYodgHo3e/ZstW7dWv7+/kpISNDn3y3Xk/89PAR7aecTDsHOmzdPFotFV1xxRT2mBYCGg2IHoF7Nnz9fkyZN0owZM5SUlKSevXrprnd/Vkm5U+e0DdfohFbHPS4lJUX33XefBg4cWM+JAaDhoNgBqFfPP/+8br31Vo0bN05du3bVeWOnyLd5F/nKqaev6nXcIVin06nRo0fr4YcfVtu2bU1IDQANA8UOQL1xOBxavXq1EhMTJUmpB4r11KJtkqTojOVq2eT4Q7CPPPKIoqKidPPNN9foccrKypSfn1/tBgDegGIHoN7k5OTI6XQqOjr68FWw61RS7lSkkavyLd8d95iffvpJb731lt54440aP87MmTMVGhpadYuNja2tpwAAbo1iB8AUH/62R7/uOqgAP6v6Gdt0vGtgCwoKdMMNN+iNN95QREREjf/sKVOmKC8vr+qWlpZWe8EBwI35mh0AgPeIiIiQ1WrV5j2Zem5zniTpgWGdtPT1f6tp06bH7L9z506lpKRoxIgRVdtcLpckydfXV9u2bVO7du2OOc5ut8tut9fRswAA90WxA1BvbDab+sTH65XV+Sq2+ql/m3Bdn9BSU0cu0d13333M/p07d9aGDRuqbZs6daoKCgr04osvMsQKAH9AsQNQr8694X59utdffhZDt8c10vjxd6moqEjjxo2TJI0ZM0YxMTGaOXOm/P391b1792rHh4WFSdIx2wEAfMYOQD1KO1isb7IaSZIcqz7SZYP6ae3atVq0aJGio6MlSampqdq/f7+ZMQGgwbIYhmGYHQKA5zMMQ6Pf/E2/7Dyg/q3DNe+2c+pt2bD8/HyFhoYqLy9PISEh9fKYAGAGztgBqBcf/paqX3YekL+fD2vBAkAdodgBqHNpB4s18+stkqT7h3ZW64hGJicCAM9EsQNQpwzD0OSF61XkcKpf68a68dzWZkcCAI9FsQNQp+auSNXPyUeGYI+/FiwAoHZQ7ADUmb2HivXEV5VDsH8f2lltGIIFgDpFsQNQJwzD0OQFG1TkcKpvK4ZgAaA+UOwA1Il5K9P0U3KO7L6VV8FaGYIFgDpHsQNQ69JzS/R41RBsJ7WNDDI5EQB4B4odgFpVOQS7XoVlFYpv1VjjzmtjdiQA8BoUOwC1av7KNP24gyFYADADxQ5ArUnPLdFjh4dg77ukk9oxBAsA9YpiB6BWHD0E26dlmG46nyFYAKhvFDsAteKtn3brxx05svn66JlrejEECwAmoNgBOGsb9ubpqUVbJUnTLu/KECwAmIRiB+CsFJZVaMK/k1TuNDS0W7SuT2hpdiQA8FoUOwBnZdqnG5VyoFjNQ/311FU9ZbEwBAsAZqHYAThjC1bv1Sdr0uVjkV4c1VthgTazIwGAV6PYATgju7ILNe2zjZKkexI7ql/rcJMTAQAodgBOW1mFUxP+vUbFDqfOaRuu8UPamx0JACCKHYAz8NR/t2nTvnw1DvTTrJG9mdoEANwExQ7Aaflua6be/nm3JOnZa3qpaai/yYkAAEdQ7ADUWEZeqe77aL0kadx5rXVRl2iTEwEAjkaxA1AjTpehe+av0cEih7o1D9HkSzubHQkA8AcUOwA18srSZP2666ACbVa9NKq37L5WsyMBAP6AYgfglFalHNSsJTskSY/8ubvasmQYALglih2Ak8orLtfEeWvldBm6Iq65ruoTY3YkAMAJUOwAnJBhGHpgwXql55aoVZNAPXZlD5YMAwA3RrEDcEIf/paqRZsy5Ge16KVRvRVk9zU7EgDgJCh2AI5ra0a+Hv1ysyTpgWGd1bNFmLmBAACnRLEDcIwSh1N3z12jsgqXBneK1E3ntTE7EgCgBih2AI7xyJeblJxVqMhgu569ppd8WDIMABoEih2Aar5av1//XpEmi0WaNTJOEUF2syMBAGqIYgegStrBYk1eWLlk2J0XtNN57SNMTgQAOB0UOwCSpHKnS/83b40KSivUu2WY7r24o9mRAACniWIHQJL0wuLtWpOaq2B/X/3zut7ys/L2AAANDe/cALRoY4Ze+X6nJOmpq3oqNjzQ5EQAgDNBsQO83KZ9ebp3/lpJ0o3nttZlPZqZGwgAcMYodoAXyy4o063vrVJJuVMDO0Ro6vAuZkcCAJwFih3gpUrLnbr9/VXal1eqthGN9PKoPvLlc3UA0KDxLg54IcMw9OAnG5SUmqsQf1+9ObavQgP9zI4FADhLFDvAC722bJcWJqXL6mPRK6Pj1TYyyOxIAIBaQLEDvMzizZl6atFWSdKMEV11fgcmIQYAT0GxA7zI1ox83TNvjQxDGp3QUjec08rsSACAWkSxA7zEgcIy3fLeKhU5nDq3XRM99KduslgsZscCANQiih3gBcoqnLrjg9Xae6hErZoE6pXRfVhZAgA8EO/sgIczDENTP9molSmHFGz31Vtj+yos0GZ2LABAHaDYAR7urZ9266PVe+VjkV76a2+1jwo2OxIAoI5Q7AAPtnRrlp74eoskaerwrhrcKcrkRACAukSxAzzUjswCTfj3GrkMaVT/WI07r7XZkQAAdYxiB3igg0UO3fzeKhWWVSihTbge/lN3roAFAC9AsQM8jKPCpTs/WK3Ug8VqGR6oV6+Pl82Xv+oA4A14twc8iGEYmvH5Jv22+6CC7JVrwIY34gpYAPAWFDvAg7z7S4r+vSJVFov0z1Fx6hjNFbAA4E0odoCHWLY9W49+uVmS9OClXXRh52iTEwEA6hvFDvAAyVmFGj83SS5Duia+hW4Z2MbsSAAAE1DsgAYut9ihW95bqYLSCvVr3ViPXckVsADgrSh2QANW7nRp/NwkpRwoVkxYgF69Pl52X6vZsQAAJqHYAQ3YI19s1s/JB9TIZtVbN/ZVRJDd7EgAABNR7IAG6p2fd+v9X/fIYpFmXddbnZuGmB0JAGAyih3QAM39LVUPf1F5Bez9Qzvr4q5cAQsAoNgBDc5/VqbpwU82SJJuG9RWd1zQ1uREAAB3QbEDGpCFSXv1wML1kqRx57XWlEs7cwUsAKAKxQ5oID5bm677Plonw5BuOKeVpl/elVIHAKiGYgc0AF9v2K9J/1knlyGN6h+rh//UjVIHADgGxQ5wc99sytD//XuNnC5DV8e30ONX9JCPD6UOAHAsih3gxpZsydT4uUmqcBm6sneMnrqqJ6UOAHBCFDvATf2wPVt3fpCkcqehEb2a65mre8rqIaVu9uzZat26tfz9/ZWQkKAVK1accN833nhDAwcOVOPGjdW4cWMlJiaedH8A8GYUO8AN/Zyco9v+tUoOp0uXdm+q56/tJV+rZ/x1nT9/viZNmqQZM2YoKSlJvXr10tChQ5WVlXXc/b///nuNGjVKS5cu1fLlyxUbG6tLLrlE6enp9ZwcANyfxTAMw+wQAH63fOcBjXt3hUrLXUrsEq1XRveRzdczSp0kJSQkqF+/fnr55ZclSS6XS7GxsZowYYImT558yuOdTqcaN26sl19+WWPGjKnRY+bn5ys0NFR5eXkKCWGFDgCey3N+WwAeYGXKQd383kqVlrs0pFOkZo/u7VGlzuFwaPXq1UpMTKza5uPjo8TERC1fvrxGf0ZxcbHKy8sVHh5+wn3KysqUn59f7QYA3sBzfmMADVxS6iHd+PYKFTucGtghQq9eHy+7r9XsWLUqJydHTqdT0dHVl0CLjo5WRkZGjf6MBx54QM2bN69WDv9o5syZCg0NrbrFxsaeVW4AaCgodoAbWJeWq7FvrVCRw6lz2zXRG2P6yt/Ps0pdbXjyySc1b948ffLJJ/L39z/hflOmTFFeXl7VLS0trR5TAoB5fM0OAHi7jel5uuGt31RQVqH+bcL15ljPLXURERGyWq3KzMystj0zM1NNmzY96bHPPvusnnzySX377bfq2bPnSfe12+2y2+1nnRcAGhrO2AEm2rI/X9e/9ZvySyvUt1VjvXNjPwXaPPffWzabTfHx8VqyZEnVNpfLpSVLlmjAgAEnPO7pp5/Wo48+qkWLFqlv3771ERUAGiTP/Q0CuLntmQUa/eZvyi0uV1xsmN4Z10+N7J7/V3LSpEkaO3as+vbtq/79+2vWrFkqKirSuHHjJEljxoxRTEyMZs6cKUl66qmnNH36dM2dO1etW7eu+ixeUFCQgoKCTHseAOCOPP+3COCGkrMK9dc3ftPBIod6tgjVezf1V7C/n9mx6sXIkSOVnZ2t6dOnKyMjQ3FxcVq0aFHVBRWpqany8fl9MOHVV1+Vw+HQ1VdfXe3PmTFjhh566KH6jA4Abo957IB6tmV/vsa+vUJZBWXq2ixEc29NUFigzexYHo157AB4C87YAfXou62ZmjB3jYocTnWKDtYHt1DqAAC1h2IH1APDMPTuLyl69MvNchnSue2a6NXR8QoN9I7hVwBA/aDYAXWswunSw19s1vu/7pEkjewbq8eu7C4/D1n7FQDgPih2QB3KLy3X3XPXaNn2bFks0uRhnXXboLayWCxmRwMAeCCKHVBH0g4W6+b3Vmp7ZqEC/KyadV2chnY7+SS8AACcDYodUAdW7zmk299fpZxCh6JD7HprbD91jwk1OxYAwMNR7IBa9vm6fbrvo3VyVLjUrXmI3hrbT01DT7yuKQAAtYViB9QSwzD0zyXJeuHb7ZKkxC7RevG6OK9YTQIA4B74jQPUgtJypyYvWK9P1+6TJN06sI0mX9pFVh8ukgAA1B+KHXCWDhSW6fb3V2vVnkOy+lj06J+7668JLc2OBQDwQhQ74CwkZxVo3LsrlXawRMH+vnp1dLzO7xBhdiwAgJei2AFn6KcdObrzw9UqKK1Qy/BAvX1jX7WPCjY7FgDAi1HsgDPw4W97NP2zTXK6DPVt1Vivj+mr8Eas+QoAMBfFDjgNTpehmV9v0Zs/7ZYkXdk7Rk9e1UN2X6vJyQAAoNgBNXaoyKG/f7xO327JkiRNurijJlzYnuXBAABug2IH1MDizZmasnCDcgrLZPP10XPX9NKIXs3NjgUAQDUUO+Ak8orL9fCXm7QwKV2S1D4qSC9cG6ceLVgeDADgfih2wAks3ZalyQvWKzO/TD4W6dZBbXVvYkf5+/F5OgCAe6LYAX9QUFqux77covmr0iRJbSIa6dlreim+VWOTkwEAcHIUO+AoP+3I0f0fr9O+vFJZLNK4c9vo70M7KcDGWToAgPuj2AGSisoqNPO/W/TBr6mSpJbhgXrm6p5KaNvE5GQAANQcxQ5e79ddB/T3j9cp7WCJJGnMgFaafGlnBdr46wEAaFj4zQWvVeJw6qlFW/XuLymSpJiwAD1zdU+d2561XgEADRPFDl5pVcpB3ffROqUcKJYkjerfUg9e1lnB/n4mJwMA4MxR7OBVSsudeu6bbXrzp90yDKlpiL+eurqnLugYaXY0AADOGsUOXmNN6iHd99E67cwukiRdHd9C0y7vqtAAztIBADwDxQ4er6zCqRe/3aE5P+yUy5Aig+168i89dFGXaLOjAQBQqyh28Ggb0/P0t/+s07bMAknSFXHN9dCfuiks0GZyMgAAah/FDh6prMKp2Ut3avbSZDldhpo0sunxK3toWPemZkcDAKDOUOzgUcqdLn28eq9e/i5Z6bmV89IN79FMj/y5m5oE2U1OBwBA3aLYwSNUOF36dO0+/XPJDqUerJzCJDrErqnDu2pEr+YmpwMAoH5Q7NCgOV2Gvly/Ty9+u0O7ciqvdo0Isuuuwe3014SW8vdjjVcAgPeg2KFBcrkMLdqUoRcWb9eOrEJJUuNAP91xQTvdMKAVy4EBALwSv/3QoBiGocWbM/XCtzu0ZX++JCnE31e3DWqrG89royA7/0sDALwXvwXRIBiGoe+3Z+uFxdu1fm+eJCnI7qubzm+jm89vwyTDAACIYgc3ZxiGftl5QM99s01JqbmSpECbVTee21q3DWrLfHQAAByFYge39duuA3pu8Xat2H1QkmT39dGYAa10+wXtFMHUJQAAHINiB7eTlHpIz3+zXT8l50iSbFYf/TWhpe4a3E5RIf4mpwMAwH1R7OA2NuzN0/OLt2nptmxJkp/Vomv7xuruC9urWWiAyekAAHB/FDuYyjAMbUjP08vfJeubzZmSJKuPRVf1idGECzsoNjzQ5IQAADQcFDuYIq+kXJ+tTde8FWnafHjaEotFuiIuRv93UQe1iWhkckIAABoeih3qjWEYWplySPNWpOqrDftVVuGSVPkZust6NNXdF7ZX+6hgk1MCANBwUexQ53IKy7Qwaa/mrUzTruyiqu0do4N0Xb+WurJ3jBo3YtoSAADOFsUOdcLpMvRTco7mrUjV4s2ZqnAZkirnoBvRs7lG9o9V79gwWSwWk5MCAOA5KHaoVftyS/SfVWn6aNVepeeWVG3vFRum6/rFakSv5iz7BQBAHeE3LM5audOlJVuyNG9lqn7Yni2j8uScQvx99Zc+LTSyX6y6NAsxNyQAAF6AYoczUlbh1K+7DurbzZn678YM5RSWVd13TttwXdevpYZ1byp/P6uJKQEA8C4UO9TYoSKHlm7L0rdbMvXDtmwVOZxV90UE2XV1fOXZOaYqAQDAHBQ7nNTunCJ9uzlTi7dkalXKQR2+BkKSFBVs10VdonVx1ygN7BApP6uPeUEBAADFDtU5XYbWpB7S4i2Z+nZzpnYeNT2JJHVuGqyLu0YrsUu0esSEyseHq1oBAHAXFDuoqKxCP+7I0bdbMvXd1iwdLHJU3efrY9E5bZsosUuULuoSzRJfAAC4MYqdFzIMQ3sPlWjZjmx9uzlTP+88IMfhVSCkyqtZh3SOUmKXaF3QKVIh/n4mpgUAADVFsfMCZRVObdqXr6Q9h7T68C2roKzaPi3DA6uGWPu2bszn5QAAaIAodh4op7CsssSlHtLqlENan55X7YycVDnE2rNFqBK7RuviLtFqHxXEKhAAADRwFLsGzukytCOroOpMXNKeQ0o5UHzMfuGNbOrTsrHiW1XeerYIZY45AAA8DMWugSkoLdfatNyqIrc2NVcFZRXV9rFYpI5RwerT6vci17pJIGfkAADwcBQ7N1ZUVqHkrEJtzyyoKnPbMguqluw6opHNqt4tG1cVubjYMIUGcMEDAADehmLnBoodRwpcoXZkFmh7ZoF2ZBVq76GS4+7fMjxQ8a0OF7mWjdWpabCszCcHAIDXo9jVoyMFbkdmobZnFVR+zSw4YYGTKpfq6hgdpG7NQxTfKlx9WoUpKti/HlMDAICGgmJXy1wuQ9mFZdp7qFgpOcXanlWg5MNFbu+hkmOGUY+ICLKrQ1SQOkYHqUN08OHvg9W4ka1+nwAAAGiwKHan6ejitvdQyeHb79+nHyqRw+k64fERQTZ1iApWx+ggtY8OVseoyiIXToEDAABniWL3By6XoZzCMqX9obDtPVSs9EMl2ptbcsyccH9k9bGoWai/YhsHqsMfzsBR4AAAQF3ximJnGIaKHE5lF5QddStVdmHl9zmFjqrtOYVlqnCdYLz0sCPFrUXjALVoHPiHrwFqGuIvX1ZuAAAA9azBFrsKp0t5JeXKLSlXbnG5DhY5lFNYVr28HfVzSbmzxn+2j0VqFhpwTGGLDQ+kuAEAALdlarFzuQwVOSpUWFahwtKKyqJWfKSsOZRXUq5DxQ7lFpcfdV/lzwWlFad+gD8IsvsqIsimyGB75S3I/vv3wXZFBvkrMtiuJkE21koFAAANzmkVO8Mw5HC6VOpwqaTcqWJHhYodThWVHS5nZRUqKP29qB3ZduT7grIKFZaWV20rctT8LNqJhPj7KizQpsaBfictbBHBNgXaGuwJSgAAgFOqcdPpPuN/Kil3ynmKz5+dUQgfi4L9fRXs76fGgX4KPVzUwgIqvw8L8FNYoJ8aB9oUenh7WKBNIf6+DIkCDdDs2bP1zDPPKCMjQ7169dJLL72k/v37n3D/jz76SNOmTVNKSoo6dOigp556Spdddlk9JgaAhqHGxa7wD+uRWn0sCvSzKsBmVZC/r4Ltvgry91WQ3VdBdj8F2a2Hf/b7/f6j9gn291Wjw9vsvj6sYwp4ifnz52vSpEmaM2eOEhISNGvWLA0dOlTbtm1TVFTUMfv/8ssvGjVqlGbOnKnLL79cc+fO1RVXXKGkpCR1797dhGcAAO7LYhgnmjK3ut05RQq0WeXvZ1Wgzcpn0ACckYSEBPXr108vv/yyJMnlcik2NlYTJkzQ5MmTj9l/5MiRKioq0pdfflm17ZxzzlFcXJzmzJlTo8fMz89XaGio8vLyFBISUjtPBADcUI3O2BmGoSY2pySnVC6VlEsnXgQLAI7P4XBo1apVmjhxovLz86u2Dxo0SMuWLdNdd911zDE///yz7r777mr7Dx48WF9++WW1bUcrKytTWVlZ1c8FBQWSdML9AaAhCA4OPuUIZ43O2B351y4AAADMUZNRhxoVO8Mwqv7F6y3y8/MVGxurtLQ0hm48GK9z/dq/f786d+6sxYsXV7tYYtq0afr555/13XffHXNMkyZNNGfOHF1zzTVV29544w09+eST2rlz53Ef549n7Pbv36/+/ftr8+bNiomJqcVnBHfC32fv4M2vc03O2NVoKNZisXjdf7wjQkJCvPa5exNe5/rh7+8vq9WqwsLCav+9c3NzFRMTc9zXoFmzZiooKKh2X35+vpo3b37ar1lwcDCvsxfg77N34HU+Pq6AAFBvbDab4uPjtWTJkqptLpdLS5Ys0YABA457zIABA6rtL0mLFy8+4f4A4M2YsRdAvZo0aZLGjh2rvn37qn///po1a5aKioo0btw4SdKYMWMUExOjmTNnSpImTpyoCy64QM8995yGDx+uefPmadWqVXr99dfNfBoA4JYodidgt9s1Y8YM2e12s6OgDvE617+RI0cqOztb06dPV0ZGhuLi4rRo0SJFR0dLklJTU+Xj8/tgwrnnnqu5c+dq6tSpevDBB9WhQwd9+umnpzWH3ZHXl9fZs/H32TvwOp9cjeexA4CGinnsAHgLPmMHAADgISh2AAAAHoJiBwAA4CEodgAAAB6CYncaysrKFBcXJ4vForVr15odB7UoJSVFN998s9q0aaOAgAC1a9dOM2bMkMPhMDsaasGRqVEiIyOVkJCgFStWmJwItWnmzJnq16+fgoODFRUVpSuuuELbtm0zOxbq0JNPPimLxaJ77rnH7Chuh2J3Gu6//341b97c7BioA1u3bpXL5dJrr72mTZs26YUXXtCcOXP04IMPmh0NZ2n+/PlVr+OPP/6oXr16aejQocrKyjI5GWrLDz/8oPHjx+vXX3/V4sWLVV5erksuuURFRUVmR0MdWLlypV577TX17NnT7ChuielOaui///2vJk2apAULFqhbt25as2aN4uLizI6FOvTMM8/o1Vdf1a5du8yOgrOQkJCgXr166Y033lBeXp6CgoIUGxurCRMmaPLkyWbHQx3Izs5WVFSUfvjhBw0aNMjsOKhFhYWF6tOnj1555RU99thjiouL06xZs8yO5VY4Y1cDmZmZuvXWW/X+++8rMDDQ7DioJ3l5eQoPDzc7Bs6Cw+HQ6tWrNXjw4KptPj4+SkxM1PLly80LhjqVl5cnSfz99UDjx4/X8OHDlZiYaHYUt8XKE6dgGIZuvPFG3XHHHerbt69SUlLMjoR6kJycrJdeeknPPvus2VFwFnJycuR0OhUVFVVte3R0tLZu3WpSKtQll8ule+65R+edd95prU4C9zdv3jwlJSVp5cqVZkdxa157xm7y5MmyWCwnvW3dulUvvfSSCgoKNGXKFLMj4wzU9HU+Wnp6uoYNG6ZrrrlGt956q0nJAZyJ8ePHa+PGjZo3b57ZUVCL0tLSNHHiRH344Yfy9/c3O45b89rP2GVnZ+vAgQMn3adt27a69tpr9cUXX8hisVRtdzqdslqtGj16tN577726joqzUNPX2WazSZL27dunwYMH65xzztG7775bbc1SNDwOh0OBgYH617/+pdGjR1ctKTZ27Fjl5ubqs88+MzsiatHdd9+tzz77TMuWLVObNm3MjoNa9Omnn+rKK6+U1Wqt2uZ0OmWxWOTj46OysrJq93kzry12NZWamqr8/Pyqn/ft26ehQ4fq448/VkJCglq0aGFiOtSm9PR0DRkyRPHx8frggw94k/AQCQkJiouL0+uvv1518UTLli119913c/GEhzAMQxMmTNAnn3yi77//Xh06dDA7EmpZQUGB9uzZU23buHHj1LlzZz3wwAMMux+Fz9idQsuWLav9HBQUJElq164dpc6DpKena/DgwWrVqpWeffZZZWdnV93XtGlTE5PhbE2aNEljxoyRJG3btk1vvvmmioqKNG7cOJOTobaMHz9ec+fO1Weffabg4GBlZGRIkkJDQxUQEGByOtSG4ODgY8pbo0aN1KRJE0rdH1DsAEmLFy9WcnKykpOTjynsnNRu2EaOHKmsrCw9/fTTOu+889S7d28tWrRI0dHRZkdDLXn11VclqdrVz5L0zjvv6MYbb6z/QICJGIoFAADwEHwyHAAAwENQ7AAAADwExQ4AAMBDUOwAAAA8BMUOAADAQ1DsAAAAPATFDgAAwENQ7AAAADwExQ4AAMBDUOwAAAA8BMUOAADAQ1DsAHisf//73woICND+/furto0bN049e/ZUXl6eickAoG5YDMMwzA4BAHXBMAzFxcVp0KBBeumllzRjxgy9/fbb+vXXXxUTE2N2PACodb5mBwCAumKxWPT444/r6quvVtOmTfXSSy/pxx9/pNQB8FicsQPg8fr06aNNmzbpm2++0QUXXGB2HACoM3zGDoBHW7RokbZu3Sqn06no6Giz4wBAneKMHQCPlZSUpMGDB+u1117Tu+++q5CQEH300UdmxwKAOsNn7AB4pJSUFA0fPlwPPvigRo0apbZt22rAgAFKSkpSnz59zI4HAHWCM3YAPM7Bgwd17rnnavDgwZozZ07V9uHDh8vpdGrRokUmpgOAukOxAwAA8BBcPAEAAOAhKHYAAAAegmIHAADgISh2AAAAHoJiBwAA4CEodgAAAB6CYgcAAOAhKHYAAAAegmIHAADgISh2AAAAHoJiBwAA4CH+H06gh190D98cAAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<sympy.plotting.plot.Plot at 0x17678c6a0>"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["import sympy\n","sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    summed_weighted_values = (coefficients * features).sum(axis=1)\n","    return torch.sigmoid(summed_weighted_values)\n"]},{"cell_type":"markdown","metadata":{},"source":["Constricting the range of our predictions within the range of what they can realistically be makes them much easier to optimize. When this is applied to every prediction each epoch should minimize our loss more effectivelyby by eliminating values that are outside the range of what our predictions can realistically be.\n","\n","This in turn allows us to substantially increase the learning rate as our loss won't be as high or fluctuate as wildly."]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.451; 0.324; 0.299; 0.209; 0.200; 0.198; 0.197; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "]},{"data":{"text/plain":["tensor(0.8258)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["coefficients = train_model(learning_rate=100)\n","calculate_accuracy(coefficients, features=validation_features)"]},{"cell_type":"markdown","metadata":{},"source":["83% a sharp improvement!"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Submission CSV"]},{"cell_type":"markdown","metadata":{},"source":["### Using a Test set\n","Before submitting to Kaggle we'll want to test the effectiveness of our data against our test set. \n","#### Why not use the Validation set?\n","This may seem similar to how we used our validation set but there's an important difference. A validation set is used to give us an unbiased evaluation of our model's performance. Unlike a training set which is biased as we're training our model on it. As we develop our model the validation set will indirectly become biased as we iterate on our model to improve the validation sets accuracy. The test set is only ever used once we have finished developing our model so it gives us an accurate assessment of how our model behaves on completely unseen data.\n","\n","- Training set - Model bias\n","- Validation Set - Developer bias\n","- Test set - No bias"]},{"cell_type":"markdown","metadata":{},"source":["### Clean Test Data"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age             86\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             1\n","Cabin          327\n","Embarked         0\n","dtype: int64"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["test_df = pd.read_csv(data_path + 'test.csv')\n","test_df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We can use the same steps we took for cleaning the training data on our test data. However it's always worth checking if there are any additional na values. Here there's an na value for Fare that needs resolving."]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Name           0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Sex_female     0\n","Sex_male       0\n","Embarked_C     0\n","Embarked_Q     0\n","Embarked_S     0\n","Pclass_1       0\n","Pclass_2       0\n","Pclass_3       0\n","LogFare        0\n","dtype: int64"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["from cgi import test\n","\n","\n","test_df.Fare.fillna(0, inplace=True)\n","test_df = substitue_na_with_modes(test_df)\n","test_df = convert_categories_to_binary_values(test_df)\n","test_df[\"LogFare\"] = np.log(test_df['Fare'] + 1)\n","test_df.isna().sum()\n"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>LogFare</th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.178064</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2.079442</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.369075</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.268252</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.586824</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0  34.5      0      0  2.178064         1           0         0         0         1           0           1           0\n","1  47.0      1      0  2.079442         0           1         0         0         1           0           0           1\n","2  62.0      0      0  2.369075         1           0         0         1         0           0           1           0\n","3  27.0      0      0  2.268252         1           0         0         0         1           0           0           1\n","4  22.0      1      1  2.586824         0           1         0         0         1           0           0           1"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["test_df[feature_names][:5]"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.4313, 0.0000, 0.0000, 0.3490, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.5875, 0.1250, 0.0000, 0.3332, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.7750, 0.0000, 0.0000, 0.3796, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000]])"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["test_features = tensor(test_df[feature_names].values, dtype=torch.float)\n","test_features = test_features / max_values\n","test_features[:3]"]},{"cell_type":"markdown","metadata":{},"source":["### Create test predictions"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=torch.int32)"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["with torch.no_grad():\n","    test_predictions = create_predictions(test_features, coefficients=coefficients)\n","test_predictions = (test_predictions > 0.5).int()\n","test_predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Create Kaggle submission\n","We can view the sample submission kaggle has given us to see how to format this."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived\n","0          892         0\n","1          893         1\n","2          894         0"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["sample_df = pd.read_csv(\"gender_submission.csv\")\n","sample_df[:3]"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"unmatched ')' (3905499227.py, line 2)","output_type":"error","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[63], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    submission_df.to_csv, index=False)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"]}],"source":["submission_df = pd.DataFrame({ \"PassengerId\": test_df[\"PassengerId\"], \"Survived\": test_predictions })\n","submission_df.to_csv( index=False)\n","submission_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.892540Z","iopub.status.busy":"2023-12-15T18:36:22.892207Z","iopub.status.idle":"2023-12-15T18:36:22.919481Z","shell.execute_reply":"2023-12-15T18:36:22.918559Z","shell.execute_reply.started":"2023-12-15T18:36:22.892511Z"},"trusted":true},"outputs":[],"source":["validation_df = pd.read_csv(data_path + \"test.csv\")\n","submission_df = pd.DataFrame()\n","submission_df[\"PassengerId\"] = validation_df[\"PassengerId\"]\n","submission_df[\"Survived\"] = serving_df[\"Survival Prediction\"].apply(lambda x: 0 if x < 0.5 else 1)\n","submission_df.to_csv(\"submission.csv\", index=False)\n","submission_df"]},{"cell_type":"markdown","metadata":{},"source":["## Neural Nets\n","The calculation above was a linear regression as we only use one set of parameters.\n","Here we'll use two sets of parameters, apply a RELU (Rectified Linear Unit) function and add them together to give us a loss. A RELU function is non-linear and simply replaces every negative number with a 0.\n","\n","The RELU is needed as adding together two linear functions just gives us another linear function which doesn't give us any more resolution for our calculation. Combinging each linear layer with a non-linear RELU allows us to keep each linear functions utility increasing our algortihms accuracy."]},{"cell_type":"markdown","metadata":{},"source":["### Create Matrix of Relu Values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.660525Z","iopub.status.busy":"2023-12-15T18:36:22.659415Z","iopub.status.idle":"2023-12-15T18:36:22.666015Z","shell.execute_reply":"2023-12-15T18:36:22.664952Z","shell.execute_reply.started":"2023-12-15T18:36:22.660473Z"},"trusted":true},"outputs":[],"source":["np.random.seed(42)\n","parameter_matrix = np.random.rand(2, input_df.shape[1]) - 0.5\n","known_survival_matrix = training_dataframe[\"Survived\"].to_numpy().reshape(-1,1)\n","inputs = input_df.to_numpy()\n","inputs"]},{"cell_type":"markdown","metadata":{},"source":["### Relu Gradient Descent (non-linear)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.667248Z","iopub.status.busy":"2023-12-15T18:36:22.666958Z","iopub.status.idle":"2023-12-15T18:36:22.786974Z","shell.execute_reply":"2023-12-15T18:36:22.785761Z","shell.execute_reply.started":"2023-12-15T18:36:22.667223Z"},"trusted":true},"outputs":[],"source":["# Gradient descent\n","for current_epoch in range(1000):\n","    # Predicted values\n","    predicted_value_matrix = np.dot(inputs, parameter_matrix.T)\n","    relu_value_matrix = np.maximum(predicted_value_matrix, 0)\n","    \n","    # Calculate error\n","    errors = relu_value_matrix - known_survival_matrix\n","    summed_errors = np.sum(errors, axis=1)\n","    if current_epoch % 100 == 0: #Print every 100th value\n","        print(summed_errors.mean())\n","    \n","    # Calculate gradient\n","    gradient = np.dot(inputs.T, summed_errors) * 2 / len(training_dataframe[\"Survived\"].to_numpy())\n","    \n","    # Update parameters\n","    parameter_matrix -= 0.01 * gradient\n","    nn_params = parameter_matrix.sum(axis=0)\n","\n","# Final parameters\n","print(f\"Optimized weights: {nn_params}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create Titanic survial predictions"]},{"cell_type":"markdown","metadata":{},"source":["Now we'll use the parameters we've calculated to try and make predictions about the survivors in our validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.788466Z","iopub.status.busy":"2023-12-15T18:36:22.788155Z","iopub.status.idle":"2023-12-15T18:36:22.814972Z","shell.execute_reply":"2023-12-15T18:36:22.813815Z","shell.execute_reply.started":"2023-12-15T18:36:22.788438Z"},"trusted":true},"outputs":[],"source":["serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.819159Z","iopub.status.busy":"2023-12-15T18:36:22.816741Z","iopub.status.idle":"2023-12-15T18:36:22.864182Z","shell.execute_reply":"2023-12-15T18:36:22.862846Z","shell.execute_reply.started":"2023-12-15T18:36:22.819120Z"},"trusted":true},"outputs":[],"source":["def estimate_missing_ages(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    mean_age = old_df[\"Age\"].mean()\n","    new_df[\"Age\"].fillna(value=mean_age, inplace=True)\n","    return new_df\n","\n","def estimate_missing_fares(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df[\"Fare\"].fillna(value=0, inplace=True)\n","    return new_df\n","    \n","def prepare_data(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df = remove_irrelevant_data(new_df)\n","    new_df = estimate_missing_ages(new_df)\n","    new_df = estimate_missing_fares(new_df)\n","    print(\"Searching for NA values:\")\n","    print(new_df.isna().any())\n","    new_df = convert_ticket_class_to_binary_values(new_df)\n","    new_df = convert_embarkation_port_to_binary_values(new_df)\n","    new_df = convert_sex_to_binary_value(new_df)\n","    new_df = convert_numeric_column_to_decimal(new_df, \"Age\")\n","    new_df = convert_numeric_column_to_decimal_with_logarithm(new_df, \"Fare\")\n","    new_df[\"Constant\"] = 1\n","    return new_df\n","    \n","serving_df = prepare_data(serving_df)\n","assert (input_df.columns == serving_df.columns).all()\n","serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.866861Z","iopub.status.busy":"2023-12-15T18:36:22.866374Z","iopub.status.idle":"2023-12-15T18:36:22.890775Z","shell.execute_reply":"2023-12-15T18:36:22.889549Z","shell.execute_reply.started":"2023-12-15T18:36:22.866818Z"},"trusted":true},"outputs":[],"source":["def create_predictions(validation_df: pd.DataFrame, optimized_weights: np.array) -> np.array:\n","    return np.dot(validation_df.to_numpy(), optimized_weights)\n","\n","serving_df[\"Survival Prediction\"] = create_predictions(serving_df, nn_params)\n","serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
