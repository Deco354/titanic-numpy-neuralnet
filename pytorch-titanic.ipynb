{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-15T18:36:11.577650Z","iopub.status.busy":"2023-12-15T18:36:11.576570Z","iopub.status.idle":"2023-12-15T18:36:11.587718Z","shell.execute_reply":"2023-12-15T18:36:11.586441Z","shell.execute_reply.started":"2023-12-15T18:36:11.577565Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on Kaggle: False\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","\n","is_kaggle = \"KAGGLE_WORKING_DIR\" in os.environ or \"/kaggle\" in os.getcwd()\n","print(\"Running on Kaggle:\", is_kaggle)\n","\n","if is_kaggle:\n","    data_path = \"/kaggle/input/titanic/\"\n","else:\n","    data_path = os.getcwd() + \"/\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","np.set_printoptions(linewidth=140)\n","torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n","pd.set_option('display.width', 140)"]},{"cell_type":"markdown","metadata":{},"source":["Based on fast.ai chapter 5 we'll now iterate on the numpy-titanic notebook by using pytorch and applying some best practices from that chapter"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Data set"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.590356Z","iopub.status.busy":"2023-12-15T18:36:11.590031Z","iopub.status.idle":"2023-12-15T18:36:11.627922Z","shell.execute_reply":"2023-12-15T18:36:11.626658Z","shell.execute_reply.started":"2023-12-15T18:36:11.590329Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n","0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n","1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n","2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n","3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n","4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n","..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n","886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n","887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n","888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n","889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n","890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n","\n","        Fare Cabin Embarked  \n","0     7.2500   NaN        S  \n","1    71.2833   C85        C  \n","2     7.9250   NaN        S  \n","3    53.1000  C123        S  \n","4     8.0500   NaN        S  \n","..       ...   ...      ...  \n","886  13.0000   NaN        S  \n","887  30.0000   B42        S  \n","888  23.4500   NaN        S  \n","889  30.0000  C148        C  \n","890   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(data_path + \"train.csv\")\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### Handling na values\n","For linear regression to work we need numerical values, n/a values are not numerical so we should check if our data set contain them."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We should avoid removing columns or rows. Even the absence of data can sometimes indicate a pattern.\n","\n","There are many ways to substitute na_values, the easiest of which is to replace na values with the mode value (the most commonly occuring value). This is a good starting point as usually the method of substituion doesn't have a large impact on our results so the mode is good to get an MVP up and running we can iterate on."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId                      1\n","Survived                       0.0\n","Pclass                         3.0\n","Name           Abbing, Mr. Anthony\n","Sex                           male\n","Age                           24.0\n","SibSp                          0.0\n","Parch                          0.0\n","Ticket                        1601\n","Fare                          8.05\n","Cabin                      B96 B98\n","Embarked                         S\n","Name: 0, dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["modes = df.mode().iloc[0]\n","modes"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Embarked       0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.fillna(modes, inplace=True)\n","df.isna().sum()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def substitue_na_with_modes(df: pd.DataFrame) -> pd.DataFrame:\n","    modes = df.mode().iloc[0]\n","    return df.fillna(modes)"]},{"cell_type":"markdown","metadata":{},"source":["### Converting Category Data to Binary Categorical Values\n"]},{"cell_type":"markdown","metadata":{},"source":["We can get view our non-numeric or numberic data using the describe function.\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Ticket</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>891</td>\n","      <td>2</td>\n","      <td>681</td>\n","      <td>147</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>347082</td>\n","      <td>B96 B98</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>577</td>\n","      <td>7</td>\n","      <td>691</td>\n","      <td>646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Name   Sex  Ticket    Cabin Embarked\n","count                       891   891     891      891      891\n","unique                      891     2     681      147        3\n","top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n","freq                          1   577       7      691      646"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=object)"]},{"cell_type":"markdown","metadata":{},"source":["Sex and Embarked only have 2, and 3 unique values respectively. It's safe to say these are categorical values.\n","\n","We should also check if any of our numbers are categorical"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>28.566970</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.199572</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n","count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n","mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n","std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n","min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n","25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n","50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n","75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n","max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=(np.number))"]},{"cell_type":"markdown","metadata":{},"source":["We can see from its quarile values that PClass is likely also categorical despite being numeric as its only values are 1, 2 or 3. We can confirm this by looking at the [data dictionary](https://www.kaggle.com/competitions/titanic/data) for the kaggle competition and by via pandas.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([3, 1, 2])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.Pclass.unique()"]},{"cell_type":"markdown","metadata":{},"source":["\n","Sex, the Passenger class and Embarking city are not measurable attributes so we should convert them to Boolean numbers that can be used as co-efficients. In the previous notebook we did this manually however this pandas can do this for us using `Dataframe.get_dummies()`"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.664903Z","iopub.status.busy":"2023-12-15T18:36:11.664551Z","iopub.status.idle":"2023-12-15T18:36:11.691977Z","shell.execute_reply":"2023-12-15T18:36:11.690666Z","shell.execute_reply.started":"2023-12-15T18:36:11.664869Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Embarked_C',\n","       'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3'],\n","      dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","df = pd.get_dummies(df, columns=categorical_feature_names, dtype=int)\n","df.columns"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0         1           0         0         0         1           0           0           1\n","1         0           1         1         0         0           1           0           0\n","2         0           1         0         0         1           0           0           1\n","3         0           1         1         0         0           0           0           1\n","4         1           0         0         0         1           0           0           1"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["dummy_column_names = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q',\n","       'Embarked_S']\n","df[dummy_column_names].head()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def convert_categories_to_binary_values(df: pd.DataFrame) -> pd.DataFrame:\n","    categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","    return pd.get_dummies(df, columns=categorical_feature_names, dtype=int)"]},{"cell_type":"markdown","metadata":{},"source":["### Handling long-tail numerical data"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib\n","df.Fare.hist()"]},{"cell_type":"markdown","metadata":{},"source":["The `Fare` column has lots of small values with the occasional very large value. Uniform normalization using the max value isn't ideal when we're dealing with lots of small values with occasional very large values as the variation between the lower numbers will be lost. To normalize the values we can use a log function (log10 here) to bring the numbers down to reasonable ranges. We must use `log10(x+1)` to avoid 0 values as `log10(0)` would give us infinity."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.771533Z","iopub.status.busy":"2023-12-15T18:36:11.771187Z","iopub.status.idle":"2023-12-15T18:36:11.795392Z","shell.execute_reply":"2023-12-15T18:36:11.794544Z","shell.execute_reply.started":"2023-12-15T18:36:11.771504Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import math\n","df['LogFare'] = np.log(df['Fare'] + 1)\n","df.LogFare.hist()"]},{"cell_type":"markdown","metadata":{},"source":["## Linear Regression"]},{"cell_type":"markdown","metadata":{},"source":["### Pytorch Tensors\n","For our gradient descent we'll be using Pytorch rather than numpy for this workbook as it will do a lot of the heavy lifting for us. Alongside Tensorflow pytorch is the most commonly used framework for machine learning."]},{"cell_type":"markdown","metadata":{},"source":["We'll start by creating Tensors for our target values (known survival status) and features (our numerical data)."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n","        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n","        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n","        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n","        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n","        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n","        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n","        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n","        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n","        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n","        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from torch import tensor\n","target_tensor = tensor(df.Survived)\n","target_tensor"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>LogFare</th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2.110213</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4.280593</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.188856</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3.990834</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.202765</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.639057</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.433987</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>24.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3.196630</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.433987</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.169054</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["      Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0    22.0      1      0  2.110213         1           0         0         0         1           0           0           1\n","1    38.0      1      0  4.280593         0           1         1         0         0           1           0           0\n","2    26.0      0      0  2.188856         0           1         0         0         1           0           0           1\n","3    35.0      1      0  3.990834         0           1         1         0         0           0           0           1\n","4    35.0      0      0  2.202765         1           0         0         0         1           0           0           1\n","..    ...    ...    ...       ...       ...         ...       ...       ...       ...         ...         ...         ...\n","886  27.0      0      0  2.639057         1           0         0         1         0           0           0           1\n","887  19.0      0      0  3.433987         0           1         1         0         0           0           0           1\n","888  24.0      1      2  3.196630         0           1         0         0         1           0           0           1\n","889  26.0      0      0  3.433987         1           0         1         0         0           1           0           0\n","890  32.0      0      0  2.169054         1           0         0         0         1           0           1           0\n","\n","[891 rows x 12 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["feature_names = ['Age', 'SibSp', 'Parch', 'LogFare'] + dummy_column_names\n","feature_df = df[feature_names]\n","feature_df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        ...,\n","        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["features = feature_df.values\n","feature_tensor = tensor(features, dtype=torch.float)\n","feature_tensor"]},{"cell_type":"markdown","metadata":{},"source":["### Normalization\n","Once all our features are numerical we need to ensure they're somewhat uniform. For Linear regression and many other ML methods having some features be much larger than others will disrupt the process. Rather than do this manually we can have Pytorch do this for us."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([80.0000,  8.0000,  6.0000,  6.2409,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["max_values, max_indices = feature_tensor.max(dim=0)\n","max_values"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.0000, 0.0000, 0.3600, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.6750, 0.0000, 0.0000, 0.6358, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        ...,\n","        [0.3125, 0.0000, 0.0000, 0.3342, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4875, 0.0000, 0.8333, 0.5456, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.3375, 0.0000, 0.0000, 0.4229, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.2375, 0.0000, 0.0000, 0.5502, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.1250, 0.3333, 0.5122, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3250, 0.0000, 0.0000, 0.5502, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.4000, 0.0000, 0.0000, 0.3476, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["feature_tensor = feature_tensor / max_values\n","feature_tensor"]},{"cell_type":"markdown","metadata":{},"source":["#### Broadcasting\n","`feature_tensor / max_values` is an example of [broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html). \n","`max_values` is a one dimensional vector with shape (12). `feature_tensor` is a 2 dimensional matrix with shape (892,12). Because `max_values` is the same size as one of `feature_tensor`'s it will be applied to all 891 rows of `feature_tensor`\n","\n","Broadcasting is useful for large datasets. The calculations are optimized and run on a GPU when available."]},{"cell_type":"markdown","metadata":{},"source":["### Prepare initial linear co-efficient values\n","For linear regression we'd like a one dimensional vector of coefficients equal to our number of rows. Unlike in previous examples we don't need a constant as our dummy variables effectively act as a constant."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.820322Z","iopub.status.busy":"2023-12-15T18:36:11.819991Z","iopub.status.idle":"2023-12-15T18:36:11.833908Z","shell.execute_reply":"2023-12-15T18:36:11.832743Z","shell.execute_reply.started":"2023-12-15T18:36:11.820295Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(442)\n","coefficient_count = feature_tensor.shape[1]\n","coefficients = torch.rand(coefficient_count) - 0.5\n","coefficients"]},{"cell_type":"markdown","metadata":{},"source":["Generally we don't want to set a manual seed so we can be aware of how stable our data is or isn't. However for the sake of this lesson I'd like to check I'm getting consistent results with the lesson plan."]},{"cell_type":"markdown","metadata":{},"source":["### Create Predictions\n","We calculate the linear function of our parameters by multiplied them against our random Coefficients then summing each row of weighted values up to create a prediction for each passenger\n","Pytorch's broadcasting can once again be used here to simplify things considerably. We'll print it out to check there aren't any weighted values that are significantly oversized."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.836343Z","iopub.status.busy":"2023-12-15T18:36:11.835997Z","iopub.status.idle":"2023-12-15T18:36:11.858845Z","shell.execute_reply":"2023-12-15T18:36:11.857637Z","shell.execute_reply.started":"2023-12-15T18:36:11.836315Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n","        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["weighted_values = feature_tensor * coefficients\n","weighted_values[:4]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["predictions = weighted_values.sum(dim=1)\n","predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate loss\n","Our loss here is the average difference between our prediction value and whether the passegner survived or not (1 or 0)."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["loss = torch.abs(predictions - target_tensor).mean()\n","loss"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def calculate_loss(features: torch.Tensor, coefficients: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    return torch.abs(predictions - targets).mean()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    return (coefficients * features).sum(axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Doing a single Gradient Descent step\n","Now we want to optimize our loss with gradient descent. This too will be significantly easier using Pytorch as it will calculate the gradient for us.\n","\n","We must tell pytorch to store the results of each coefficient calculation so we can get the gradients from it later."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.860841Z","iopub.status.busy":"2023-12-15T18:36:11.860409Z","iopub.status.idle":"2023-12-15T18:36:22.655866Z","shell.execute_reply":"2023-12-15T18:36:22.654577Z","shell.execute_reply.started":"2023-12-15T18:36:11.860799Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["coefficients.requires_grad_()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382, grad_fn=<MeanBackward0>)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss"]},{"cell_type":"markdown","metadata":{},"source":["The loss is in a tensor where can ask Pytorch to calculate the gradient by calling `backward()`"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["loss.backward()\n","coefficients.grad"]},{"cell_type":"markdown","metadata":{},"source":["Here we perform one gradient descent step\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.5197)\n"]}],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss.backward\n","with torch.no_grad():\n","    coefficients.sub_(coefficients.grad * 0.1)\n","    coefficients.grad.zero_()\n","    print(calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor))"]},{"cell_type":"markdown","metadata":{},"source":["A few points:\n","1. `torch.no_grad()` is required to ensure the parameter update step is peformed without tracking gradients. We want to track gradients for the forward and backward steps but not when directly modifying the parameters\n","2. `coefficients.sub_(coefficients.grad * 0.1)` reduces the coefficients by their gradient to the loss. More significant features will be reduced more. \n","3. Both `sub_` and `zero_` operations are done in place for memory efficiency and to preserve the tensors memory graph (this is also ensured by `torch.no_grad()` although it's good practice when working with tensors).\n","4. `coefficients.grad.zero_()` sets our gradients to zero. This is necessary as if we were to do another backpass the new gradients would be added to the old ones."]},{"cell_type":"markdown","metadata":{},"source":["### Creating a validation set\n"]},{"cell_type":"markdown","metadata":{},"source":["Before we begin training we need a validation set to compare our training data against."]},{"cell_type":"markdown","metadata":{},"source":["I've deviated from the [fast.ai kaggle workbook](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch) as they split their validation set using the fastai library to keep things consistent for their next chapter. I'm interested in primarily learning Pytorch so I'm going to split the dataset without the fastai library. However so I can check if my results match fast.ai's I'm going to include their splitter here it will be used if `use_fastai_splitter` is set to `True` so I can check my results are consistent with the fast.ai tutorials."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["from numpy import int64\n","from fastai.data.transforms import RandomSplitter\n","\n","def split_data_with_fastai(df: pd.DataFrame) -> tuple[np.int64, np.int64]:\n","    return RandomSplitter(seed=42)(df)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["First we'll split our data"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["(713, 178)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["use_fastai_splitter = True\n","total_passengers = feature_tensor.size(0)\n","training_set_size = int(total_passengers * 0.8)\n","\n","if use_fastai_splitter:\n","    train_indices, validation_indices = split_data_with_fastai(df)\n","else:\n","    randomized_indices = torch.randperm(total_passengers)\n","    train_indices = randomized_indices[:training_set_size]\n","    validation_indices = randomized_indices[training_set_size:]\n","\n","training_features = feature_tensor[train_indices]\n","validation_features = feature_tensor[validation_indices]\n","training_targets = target_tensor[train_indices]\n","validation_targets = target_tensor[validation_indices]\n","len(training_features), len(validation_features)"]},{"cell_type":"markdown","metadata":{},"source":["This note book doesn't use Pytorch's `Dataset`s. We'd likely use these in a real project although for this example we're keeping things a bit barer than normal so we can see the process."]},{"cell_type":"markdown","metadata":{},"source":["We'll add what we've done so far in to functions to make things easier to read and re-usable."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["def update_coefficients(coefficients: torch.Tensor, learning_rate):\n","    coefficients.sub_(coefficients.grad * learning_rate)\n","    coefficients.grad.zero_()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def one_epoch(coefficients, learning_rate):\n","    loss = calculate_loss(training_features, coefficients, training_targets)\n","    loss.backward()\n","    with torch.no_grad():\n","        update_coefficients(coefficients, learning_rate=learning_rate)\n","        \n","    print(f\"{loss:.3f}\", end=\"; \")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def generate_coefficients(features: torch.Tensor) -> torch.Tensor:\n","    coefficient_count = features.shape[1]\n","    coefficients = torch.rand(coefficient_count) - 0.5\n","    coefficients.requires_grad_()\n","    return coefficients"]},{"cell_type":"markdown","metadata":{},"source":["Now to train the model"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def train_model(epoch_count=30, learning_rate=0.1):\n","    coefficients = generate_coefficients(training_features)\n","    for i in range(epoch_count):\n","        one_epoch(coefficients, learning_rate=learning_rate)\n","    return coefficients"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.550; 0.494; 0.446; 0.400; 0.385; 0.392; 0.348; 0.351; 0.365; 0.327; 0.345; 0.310; 0.326; 0.292; 0.308; 0.280; 0.323; 0.269; "]},{"data":{"text/plain":["tensor([ 0.0114, -0.1277, -0.0490,  0.2052,  0.0136,  0.7174,  0.0278, -0.1602, -0.1642,  0.1394,  0.3767,  0.2155], requires_grad=True)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["coefficients = train_model(epoch_count=18, learning_rate=0.2)\n","coefficients"]},{"cell_type":"markdown","metadata":{},"source":["We can see below that our models has optimized our weights to reduce our loss. From this we can see that the model believes"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature</th>\n","      <th>Coefficient</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Age</td>\n","      <td>0.011448</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SibSp</td>\n","      <td>-0.127748</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Parch</td>\n","      <td>-0.049038</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LogFare</td>\n","      <td>0.205193</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sex_male</td>\n","      <td>0.013623</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sex_female</td>\n","      <td>0.717442</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Pclass_1</td>\n","      <td>0.027782</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Pclass_2</td>\n","      <td>-0.160171</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Pclass_3</td>\n","      <td>-0.164208</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Embarked_C</td>\n","      <td>0.139427</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Embarked_Q</td>\n","      <td>0.376680</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Embarked_S</td>\n","      <td>0.215454</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Feature  Coefficient\n","0          Age     0.011448\n","1        SibSp    -0.127748\n","2        Parch    -0.049038\n","3      LogFare     0.205193\n","4     Sex_male     0.013623\n","5   Sex_female     0.717442\n","6     Pclass_1     0.027782\n","7     Pclass_2    -0.160171\n","8     Pclass_3    -0.164208\n","9   Embarked_C     0.139427\n","10  Embarked_Q     0.376680\n","11  Embarked_S     0.215454"]},"metadata":{},"output_type":"display_data"}],"source":["def show_coeffs(): \n","    coeff_array = [coeff.item() for coeff in coefficients]\n","    coeff_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coeff_array})\n","    display(coeff_df)\n","show_coeffs()"]},{"cell_type":"markdown","metadata":{},"source":["### Measuring accuracy"]},{"cell_type":"markdown","metadata":{},"source":["To view our accuracy we'll now use our validation set. We'll create predictions using our newly trained coefficients and see how accurate they are."]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1.0226, 0.3008, 0.0616, 0.2132, 0.1593, 0.1594, 0.7728, 0.8635, 0.0960, 0.7756], grad_fn=<SliceBackward0>)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["predictions = create_predictions(validation_features, coefficients=coefficients)\n","predictions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["If our predictions is >0.5 and the passegner surivied we're correct. If the passenger died we want a prediction < 0.5. 0 = died, 1 = survived. This code merely rounds our predictions to whichever of these values is closest"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.7865)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["results = validation_targets.bool() == (predictions>0.5)\n","results.float().mean()"]},{"cell_type":"markdown","metadata":{},"source":["We're 79% accurate which is pretty good going."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["def calculate_accuracy(coefficients) -> float:\n","    predictions = create_predictions(validation_features, coefficients=coefficients)\n","    results = validation_targets.bool() == (predictions>0.5)\n","    return results.float().mean()"]},{"cell_type":"markdown","metadata":{},"source":["### Sigmoid\n","When creating predictions that are between 0 and 1 we can increase our accuracy by using the sigmoid function which moves all our values between 0 and 1 and larger negative or positives values will respectively asymptotically converge towards 0 or 1."]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<sympy.plotting.plot.Plot at 0x16845d6c0>"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["import sympy\n","sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    summed_weighted_values = (coefficients * features).sum(axis=1)\n","    return torch.sigmoid(summed_weighted_values)\n"]},{"cell_type":"markdown","metadata":{},"source":["Constricting the range of our predictions within the range of what they can realistically be makes them much easier to optimize. When this is applied to every prediction each epoch should minimize our loss more effectivelyby by eliminating values that are outside the range of what our predictions can realistically be.\n","\n","This in turn allows us to substantially increase the learning rate as our loss won't be as high or fluctuate as wildly."]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.451; 0.324; 0.299; 0.209; 0.200; 0.198; 0.197; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "]},{"data":{"text/plain":["tensor(0.8258)"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["coefficients = train_model(learning_rate=100)\n","calculate_accuracy(coefficients)"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Submission CSV"]},{"cell_type":"markdown","metadata":{},"source":["### Using a Test set\n","Before submitting to Kaggle we'll want to test the effectiveness of our data against our test set. \n","#### Why not use the Validation set?\n","This may seem similar to how we used our validation set but there's an important difference. A validation set is used to give us an unbiased evaluation of our model's performance. Unlike a training set which is biased as we're training our model on it. As we develop our model the validation set will indirectly become biased as we iterate on our model to improve the validation sets accuracy. The test set is only ever used once we have finished developing our model so it gives us an accurate assessment of how our model behaves on completely unseen data.\n","\n","- Training set - Model bias\n","- Validation Set - Developer bias\n","- Test set - No bias"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age             86\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             1\n","Cabin          327\n","Embarked         0\n","dtype: int64"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["test_df = pd.read_csv(data_path + 'test.csv')\n","test_df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We can use the same steps we took for cleaning the training data on our test data. However it's always worth checking if there are any additional na values. Here there's an na value for Fare that needs resolving."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>LogFare</th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.110213</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4.280593</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.188856</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.990834</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.202765</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0  34.5      0      0  2.110213         1           0         0         0         1           0           1           0\n","1  47.0      1      0  4.280593         0           1         0         0         1           0           0           1\n","2  62.0      0      0  2.188856         1           0         0         1         0           0           1           0\n","3  27.0      0      0  3.990834         1           0         0         0         1           0           0           1\n","4  22.0      1      1  2.202765         0           1         0         0         1           0           0           1"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["test_df.Fare.fillna(0, inplace=True)\n","test_df = convert_categories_to_binary_values(test_df)\n","test_df[\"LogFare\"] = np.log(df['Fare'] + 1)\n","test_df = test_df[feature_names]\n","test_df[:5]"]},{"cell_type":"markdown","metadata":{},"source":["### Create Kaggle submission\n","We can view the sample submission kaggle has given us to see how to format this."]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived\n","0          892         0\n","1          893         1\n","2          894         0"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["sample_df = pd.read_csv(\"gender_submission.csv\")\n","sample_df[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.892540Z","iopub.status.busy":"2023-12-15T18:36:22.892207Z","iopub.status.idle":"2023-12-15T18:36:22.919481Z","shell.execute_reply":"2023-12-15T18:36:22.918559Z","shell.execute_reply.started":"2023-12-15T18:36:22.892511Z"},"trusted":true},"outputs":[],"source":["validation_df = pd.read_csv(data_path + \"test.csv\")\n","submission_df = pd.DataFrame()\n","submission_df[\"PassengerId\"] = validation_df[\"PassengerId\"]\n","submission_df[\"Survived\"] = serving_df[\"Survival Prediction\"].apply(lambda x: 0 if x < 0.5 else 1)\n","submission_df.to_csv(\"submission.csv\", index=False)\n","submission_df"]},{"cell_type":"markdown","metadata":{},"source":["## Neural Nets\n","The calculation above was a linear regression as we only use one set of parameters.\n","Here we'll use two sets of parameters, apply a RELU (Rectified Linear Unit) function and add them together to give us a loss. A RELU function is non-linear and simply replaces every negative number with a 0.\n","\n","The RELU is needed as adding together two linear functions just gives us another linear function which doesn't give us any more resolution for our calculation. Combinging each linear layer with a non-linear RELU allows us to keep each linear functions utility increasing our algortihms accuracy."]},{"cell_type":"markdown","metadata":{},"source":["### Create Matrix of Relu Values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.660525Z","iopub.status.busy":"2023-12-15T18:36:22.659415Z","iopub.status.idle":"2023-12-15T18:36:22.666015Z","shell.execute_reply":"2023-12-15T18:36:22.664952Z","shell.execute_reply.started":"2023-12-15T18:36:22.660473Z"},"trusted":true},"outputs":[],"source":["np.random.seed(42)\n","parameter_matrix = np.random.rand(2, input_df.shape[1]) - 0.5\n","known_survival_matrix = training_dataframe[\"Survived\"].to_numpy().reshape(-1,1)\n","inputs = input_df.to_numpy()\n","inputs"]},{"cell_type":"markdown","metadata":{},"source":["### Relu Gradient Descent (non-linear)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.667248Z","iopub.status.busy":"2023-12-15T18:36:22.666958Z","iopub.status.idle":"2023-12-15T18:36:22.786974Z","shell.execute_reply":"2023-12-15T18:36:22.785761Z","shell.execute_reply.started":"2023-12-15T18:36:22.667223Z"},"trusted":true},"outputs":[],"source":["# Gradient descent\n","for current_epoch in range(1000):\n","    # Predicted values\n","    predicted_value_matrix = np.dot(inputs, parameter_matrix.T)\n","    relu_value_matrix = np.maximum(predicted_value_matrix, 0)\n","    \n","    # Calculate error\n","    errors = relu_value_matrix - known_survival_matrix\n","    summed_errors = np.sum(errors, axis=1)\n","    if current_epoch % 100 == 0: #Print every 100th value\n","        print(summed_errors.mean())\n","    \n","    # Calculate gradient\n","    gradient = np.dot(inputs.T, summed_errors) * 2 / len(training_dataframe[\"Survived\"].to_numpy())\n","    \n","    # Update parameters\n","    parameter_matrix -= 0.01 * gradient\n","    nn_params = parameter_matrix.sum(axis=0)\n","\n","# Final parameters\n","print(f\"Optimized weights: {nn_params}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create Titanic survial predictions"]},{"cell_type":"markdown","metadata":{},"source":["Now we'll use the parameters we've calculated to try and make predictions about the survivors in our validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.788466Z","iopub.status.busy":"2023-12-15T18:36:22.788155Z","iopub.status.idle":"2023-12-15T18:36:22.814972Z","shell.execute_reply":"2023-12-15T18:36:22.813815Z","shell.execute_reply.started":"2023-12-15T18:36:22.788438Z"},"trusted":true},"outputs":[],"source":["serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.819159Z","iopub.status.busy":"2023-12-15T18:36:22.816741Z","iopub.status.idle":"2023-12-15T18:36:22.864182Z","shell.execute_reply":"2023-12-15T18:36:22.862846Z","shell.execute_reply.started":"2023-12-15T18:36:22.819120Z"},"trusted":true},"outputs":[],"source":["def estimate_missing_ages(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    mean_age = old_df[\"Age\"].mean()\n","    new_df[\"Age\"].fillna(value=mean_age, inplace=True)\n","    return new_df\n","\n","def estimate_missing_fares(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df[\"Fare\"].fillna(value=0, inplace=True)\n","    return new_df\n","    \n","def prepare_data(old_df: pd.DataFrame) -> pd.DataFrame:\n","    new_df = old_df.copy()\n","    new_df = remove_irrelevant_data(new_df)\n","    new_df = estimate_missing_ages(new_df)\n","    new_df = estimate_missing_fares(new_df)\n","    print(\"Searching for NA values:\")\n","    print(new_df.isna().any())\n","    new_df = convert_ticket_class_to_binary_values(new_df)\n","    new_df = convert_embarkation_port_to_binary_values(new_df)\n","    new_df = convert_sex_to_binary_value(new_df)\n","    new_df = convert_numeric_column_to_decimal(new_df, \"Age\")\n","    new_df = convert_numeric_column_to_decimal_with_logarithm(new_df, \"Fare\")\n","    new_df[\"Constant\"] = 1\n","    return new_df\n","    \n","serving_df = prepare_data(serving_df)\n","assert (input_df.columns == serving_df.columns).all()\n","serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:22.866861Z","iopub.status.busy":"2023-12-15T18:36:22.866374Z","iopub.status.idle":"2023-12-15T18:36:22.890775Z","shell.execute_reply":"2023-12-15T18:36:22.889549Z","shell.execute_reply.started":"2023-12-15T18:36:22.866818Z"},"trusted":true},"outputs":[],"source":["def create_predictions(validation_df: pd.DataFrame, optimized_weights: np.array) -> np.array:\n","    return np.dot(validation_df.to_numpy(), optimized_weights)\n","\n","serving_df[\"Survival Prediction\"] = create_predictions(serving_df, nn_params)\n","serving_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
