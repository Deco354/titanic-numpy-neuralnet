{"cells":[{"cell_type":"markdown","metadata":{},"source":["This is a copy of my [Pytorch-titanic Notebook](https://www.kaggle.com/code/declanmckenna/pytorch-titanic) but it will apply weight decay to our linear model. Skip to the end to see how to apply weight decay to a model. I've removed all the text prior to this section. Check out [the original notebook](https://www.kaggle.com/code/declanmckenna/pytorch-titanic) if you'd like to see how to create a model from scratch in Pytorch."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-15T18:36:11.577650Z","iopub.status.busy":"2023-12-15T18:36:11.576570Z","iopub.status.idle":"2023-12-15T18:36:11.587718Z","shell.execute_reply":"2023-12-15T18:36:11.586441Z","shell.execute_reply.started":"2023-12-15T18:36:11.577565Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","\n","is_kaggle = \"KAGGLE_WORKING_DIR\" in os.environ or \"/kaggle\" in os.getcwd()\n","print(\"Running on Kaggle:\", is_kaggle)\n","\n","if is_kaggle:\n","    data_path = \"/kaggle/input/titanic/\"\n","else:\n","    data_path = os.getcwd() + \"/\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","np.set_printoptions(linewidth=140)\n","torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n","pd.set_option('display.width', 140)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.590356Z","iopub.status.busy":"2023-12-15T18:36:11.590031Z","iopub.status.idle":"2023-12-15T18:36:11.627922Z","shell.execute_reply":"2023-12-15T18:36:11.626658Z","shell.execute_reply.started":"2023-12-15T18:36:11.590329Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(data_path + \"train.csv\")\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["modes = df.mode().iloc[0]\n","modes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.fillna(modes, inplace=True)\n","df.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def substitue_na_with_modes(df: pd.DataFrame) -> pd.DataFrame:\n","    modes = df.mode().iloc[0]\n","    return df.fillna(modes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.describe(include=[object])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.describe(include=[np.number])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.Pclass.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.664903Z","iopub.status.busy":"2023-12-15T18:36:11.664551Z","iopub.status.idle":"2023-12-15T18:36:11.691977Z","shell.execute_reply":"2023-12-15T18:36:11.690666Z","shell.execute_reply.started":"2023-12-15T18:36:11.664869Z"},"trusted":true},"outputs":[],"source":["categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","df = pd.get_dummies(df, columns=categorical_feature_names, dtype=int)\n","df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dummy_column_names = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q',\n","       'Embarked_S']\n","df[dummy_column_names].head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convert_categories_to_binary_values(df: pd.DataFrame) -> pd.DataFrame:\n","    categorical_feature_names = ['Sex', 'Embarked', 'Pclass']\n","    return pd.get_dummies(df, columns=categorical_feature_names, dtype=int)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib\n","df.Fare.hist()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.771533Z","iopub.status.busy":"2023-12-15T18:36:11.771187Z","iopub.status.idle":"2023-12-15T18:36:11.795392Z","shell.execute_reply":"2023-12-15T18:36:11.794544Z","shell.execute_reply.started":"2023-12-15T18:36:11.771504Z"},"trusted":true},"outputs":[],"source":["import math\n","df['LogFare'] = np.log(df['Fare'] + 1)\n","df.LogFare.hist()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import tensor\n","target_tensor = tensor(df.Survived)\n","target_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_names = ['Age', 'SibSp', 'Parch', 'LogFare'] + dummy_column_names\n","feature_df = df[feature_names]\n","feature_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = feature_df.values\n","feature_tensor = tensor(features, dtype=torch.float)\n","feature_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_values, max_indices = feature_tensor.max(dim=0)\n","max_values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_tensor = feature_tensor / max_values\n","feature_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.820322Z","iopub.status.busy":"2023-12-15T18:36:11.819991Z","iopub.status.idle":"2023-12-15T18:36:11.833908Z","shell.execute_reply":"2023-12-15T18:36:11.832743Z","shell.execute_reply.started":"2023-12-15T18:36:11.820295Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(442)\n","feature_count = feature_tensor.shape[1]\n","coefficients = torch.rand(feature_count) - 0.5\n","coefficients"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.836343Z","iopub.status.busy":"2023-12-15T18:36:11.835997Z","iopub.status.idle":"2023-12-15T18:36:11.858845Z","shell.execute_reply":"2023-12-15T18:36:11.857637Z","shell.execute_reply.started":"2023-12-15T18:36:11.836315Z"},"trusted":true},"outputs":[],"source":["weighted_values = feature_tensor * coefficients\n","weighted_values[:4]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = weighted_values.sum(dim=1)\n","predictions[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss = torch.abs(predictions - target_tensor).mean()\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    return (coefficients * features).sum(dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_loss(features: torch.Tensor, coefficients: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    return torch.abs(predictions - targets).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:36:11.860841Z","iopub.status.busy":"2023-12-15T18:36:11.860409Z","iopub.status.idle":"2023-12-15T18:36:22.655866Z","shell.execute_reply":"2023-12-15T18:36:22.654577Z","shell.execute_reply.started":"2023-12-15T18:36:11.860799Z"},"trusted":true},"outputs":[],"source":["coefficients.requires_grad_()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss.backward()\n","coefficients.grad"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss = calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor)\n","loss.backward\n","with torch.no_grad():\n","    assert coefficients.grad is not None\n","    coefficients.sub_(coefficients.grad * 0.1)\n","    coefficients.grad.zero_()\n","    print(calculate_loss(feature_tensor, coefficients=coefficients, targets=target_tensor))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from random import Random\n","from numpy import int64\n","from fastai.data.transforms import RandomSplitter\n","from typing import Tuple, List, cast\n","from fastcore.foundation import L\n","from torch import Tensor\n","\n","def split_data_with_fastai(df: pd.DataFrame) -> Tuple[Tensor,Tensor]:\n","    train_indices, validation_indices = RandomSplitter(seed=42)(df)\n","    return torch.tensor(train_indices, dtype=torch.int64), torch.tensor(validation_indices, dtype=torch.int64)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["use_fastai_splitter = True\n","total_passengers = feature_tensor.size(0)\n","training_set_size = int(total_passengers * 0.8)\n","\n","if use_fastai_splitter:\n","    train_indices, validation_indices = split_data_with_fastai(df)\n","else:\n","    randomized_indices = torch.randperm(total_passengers)\n","    train_indices = randomized_indices[:training_set_size]\n","    validation_indices = randomized_indices[training_set_size:]\n","\n","training_features = feature_tensor[train_indices]\n","validation_features = feature_tensor[validation_indices]\n","training_targets = target_tensor[train_indices]\n","validation_targets = target_tensor[validation_indices]\n","len(training_features), len(validation_features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def update_coefficients(coefficients, learning_rate):\n","    coefficients.sub_(coefficients.grad * learning_rate)\n","    coefficients.grad.zero_()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def one_epoch(coefficients, learning_rate):\n","    loss = calculate_loss(training_features, coefficients, training_targets)\n","    loss.backward()\n","    with torch.no_grad():\n","        update_coefficients(coefficients, learning_rate=learning_rate)\n","        \n","    print(f\"{loss:.3f}\", end=\"; \")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_coefficients(features: torch.Tensor) -> torch.Tensor:\n","    coefficient_count = features.shape[1]\n","    coefficients = torch.rand(coefficient_count) - 0.5\n","    coefficients.requires_grad_()\n","    return coefficients"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_model(epoch_count=30, learning_rate=0.1):\n","    coefficients = generate_coefficients(training_features)\n","    for i in range(epoch_count):\n","        one_epoch(coefficients, learning_rate=learning_rate)\n","    return coefficients"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coefficients = train_model(epoch_count=18, learning_rate=0.2)\n","coefficients"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def show_coeffs(): \n","    coeff_array = [coeff.item() for coeff in coefficients]\n","    coeff_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coeff_array})\n","    display(coeff_df)\n","show_coeffs()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = create_predictions(validation_features, coefficients=coefficients)\n","predictions[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = validation_targets.bool() == (predictions>0.5)\n","results.float().mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import Tensor\n","\n","\n","def calculate_accuracy(coefficients, features: torch.Tensor) -> Tensor:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    results = validation_targets.bool() == (predictions>0.5)\n","    return results.float().mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sympy\n","sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_predictions(features: torch.Tensor, coefficients: torch.Tensor) -> torch.Tensor:\n","    summed_weighted_values = (coefficients * features).sum(dim=1)\n","    return torch.sigmoid(summed_weighted_values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coefficients = train_model(learning_rate=100)\n","calculate_accuracy(coefficients, features=validation_features)"]},{"cell_type":"markdown","metadata":{},"source":["## Weight Decay\n","Often our loss will go down but our validation loss will begin to increase. This is usually a sign of overfitting. One of those most basic ways to prevent overfitting is weight decay.\n","\n","We add all the weights squared to our loss. This will hinder our training but helps prevent overfitting by forcing our weights to get smaller. Smaller weights mean less resolution in our models solutions, as demonstrated a solution that fits our training data too closely will over-fit\n","\n","![overfitting-illustration](overfitting-example.webp)"]},{"cell_type":"markdown","metadata":{},"source":["Below is a simply implementation of weight decay"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_loss(features: torch.Tensor, coefficients: torch.Tensor, targets: torch.Tensor, weight_decay: float) -> torch.Tensor:\n","    predictions = create_predictions(features, coefficients=coefficients)\n","    loss = torch.abs(predictions - targets).mean()\n","    wd_loss = loss + weight_decay * (coefficients ** 2).sum()\n","    return wd_loss"]},{"cell_type":"markdown","metadata":{},"source":["We also need to update the functions that call our calculate loss function to pass the weight decay value in. I've also updated our loss printing so we can see both the validation loss and the loss.\n","\n","When your loss goes down but your validation loss goes up this is usually a sign of overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def one_epoch(coefficients, learning_rate, weight_decay:float):\n","    loss = calculate_loss(training_features, coefficients, training_targets, weight_decay)\n","    loss.backward()\n","    with torch.no_grad():\n","        update_coefficients(coefficients, learning_rate=learning_rate)\n","        validaton_loss = calculate_loss(validation_features, coefficients, validation_targets, weight_decay)\n","        \n","    print(f\"loss: {loss:.3f}, val_loss: {validaton_loss}\", end=\";\\n\")\n","    \n","def train_model(epoch_count=30, learning_rate=0.1, weight_decay:float=0.0):\n","    coefficients = generate_coefficients(training_features)\n","    for i in range(epoch_count):\n","        one_epoch(coefficients, learning_rate=learning_rate, weight_decay=weight_decay)\n","    return coefficients"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coefficients = train_model(learning_rate=100, weight_decay=0.001)\n","calculate_accuracy(coefficients, features=validation_features)"]},{"cell_type":"markdown","metadata":{},"source":["In this case our results got worse, adding weight decay will make your model train less accurately but it's a good weapon to have in cases where your model is overfitting, this simple linear model that has relevant engineered features isn't going to overfit so our weight decay implementation is merely an example rather than an improvement here."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
